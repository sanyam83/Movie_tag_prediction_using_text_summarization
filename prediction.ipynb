{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "assignment 2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "nJTuwZ9itJJi",
        "outputId": "b54a216f-5fba-4daf-98da-5f195b0ad8a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m18NihhuvGhS",
        "outputId": "e7fd7a8c-9848-473d-9c5e-dbaec0129565",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "#importing libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import seaborn as sns\n",
        "plt.style.use('ggplot')\n",
        "import re\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "from nltk.util import ngrams\n",
        "from nltk.corpus import stopwords\n",
        "stop=set(stopwords.words('english'))\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from collections import defaultdict\n",
        "from collections import  Counter\n",
        "from sklearn.model_selection import train_test_split\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "from keras.models import Sequential\n",
        "from keras.initializers import Constant\n",
        "from keras.layers import (LSTM, \n",
        "                          Embedding, \n",
        "                          BatchNormalization,\n",
        "                          Dense, \n",
        "                          TimeDistributed, \n",
        "                          Dropout, \n",
        "                          Bidirectional,\n",
        "                          Flatten, \n",
        "                          GlobalMaxPool1D)\n",
        "from nltk.tokenize import word_tokenize\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
        "from keras.optimizers import Adam\n",
        "from sklearn.metrics import (\n",
        "    precision_score, \n",
        "    recall_score, \n",
        "    f1_score, \n",
        "    classification_report,\n",
        "    accuracy_score\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eh3m0fgyxKyu"
      },
      "source": [
        "movies = pd.read_csv(\"/content/drive/My Drive/movie.csv\")\n",
        "genome_scores = pd.read_csv(\"/content/drive/My Drive/genome_scores.csv\")\n",
        "genome_tags = pd.read_csv(\"/content/drive/My Drive/genome_tags.csv\")\n",
        "plot = pd.read_csv(\"/content/drive/My Drive/wiki_movie_plots_deduped.csv\")\n",
        "reviews = pd.read_csv(\"/content/drive/My Drive/metacritic_reviews.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eGslWtCbxLkV"
      },
      "source": [
        "plot.rename(columns={'Title': 'title'}, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yoW5XyxDxQ0y",
        "outputId": "3b3e3312-8d18-470b-9aeb-d940e95be997",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        "movies"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>movieId</th>\n",
              "      <th>title</th>\n",
              "      <th>genres</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Toy Story (1995)</td>\n",
              "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>Jumanji (1995)</td>\n",
              "      <td>Adventure|Children|Fantasy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>Grumpier Old Men (1995)</td>\n",
              "      <td>Comedy|Romance</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>Waiting to Exhale (1995)</td>\n",
              "      <td>Comedy|Drama|Romance</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>Father of the Bride Part II (1995)</td>\n",
              "      <td>Comedy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27273</th>\n",
              "      <td>131254</td>\n",
              "      <td>Kein Bund für's Leben (2007)</td>\n",
              "      <td>Comedy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27274</th>\n",
              "      <td>131256</td>\n",
              "      <td>Feuer, Eis &amp; Dosenbier (2002)</td>\n",
              "      <td>Comedy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27275</th>\n",
              "      <td>131258</td>\n",
              "      <td>The Pirates (2014)</td>\n",
              "      <td>Adventure</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27276</th>\n",
              "      <td>131260</td>\n",
              "      <td>Rentun Ruusu (2001)</td>\n",
              "      <td>(no genres listed)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27277</th>\n",
              "      <td>131262</td>\n",
              "      <td>Innocence (2014)</td>\n",
              "      <td>Adventure|Fantasy|Horror</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>27278 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       movieId  ...                                       genres\n",
              "0            1  ...  Adventure|Animation|Children|Comedy|Fantasy\n",
              "1            2  ...                   Adventure|Children|Fantasy\n",
              "2            3  ...                               Comedy|Romance\n",
              "3            4  ...                         Comedy|Drama|Romance\n",
              "4            5  ...                                       Comedy\n",
              "...        ...  ...                                          ...\n",
              "27273   131254  ...                                       Comedy\n",
              "27274   131256  ...                                       Comedy\n",
              "27275   131258  ...                                    Adventure\n",
              "27276   131260  ...                           (no genres listed)\n",
              "27277   131262  ...                     Adventure|Fantasy|Horror\n",
              "\n",
              "[27278 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HuyA1i6nxSNd"
      },
      "source": [
        "movies['title'] = movies['title'].str.replace(r\"\\(.*\\)\",\"\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BkbPtvF_xkGP"
      },
      "source": [
        "movies['title'] = movies['title'].str.rstrip()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IEnsvI7Vxk2Y"
      },
      "source": [
        "df = pd.merge(movies, plot ,  how='left', left_on='title', right_on='title')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jq6ZzZs1xkek"
      },
      "source": [
        "df = df[df['Plot'].notna()]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pvlFLdz2xkVs"
      },
      "source": [
        "df = df.reset_index()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aemW9o96xkA_",
        "outputId": "cbc90006-544f-4005-be5a-059771a0b543",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>movieId</th>\n",
              "      <th>title</th>\n",
              "      <th>genres</th>\n",
              "      <th>Release Year</th>\n",
              "      <th>Origin/Ethnicity</th>\n",
              "      <th>Director</th>\n",
              "      <th>Cast</th>\n",
              "      <th>Genre</th>\n",
              "      <th>Wiki Page</th>\n",
              "      <th>Plot</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>Toy Story</td>\n",
              "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
              "      <td>1995.0</td>\n",
              "      <td>American</td>\n",
              "      <td>John Lasseter</td>\n",
              "      <td>Tim Allen, Tom Hanks (voices)</td>\n",
              "      <td>animated film</td>\n",
              "      <td>https://en.wikipedia.org/wiki/Toy_Story</td>\n",
              "      <td>In a world where toys are living things who pr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>Jumanji</td>\n",
              "      <td>Adventure|Children|Fantasy</td>\n",
              "      <td>1995.0</td>\n",
              "      <td>American</td>\n",
              "      <td>Joe Johnston</td>\n",
              "      <td>Robin Williams, Bonnie Hunt, Kirsten Dunst, Br...</td>\n",
              "      <td>family, fantasy</td>\n",
              "      <td>https://en.wikipedia.org/wiki/Jumanji_(film)</td>\n",
              "      <td>In 1869, near Brantford, New Hampshire, two br...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>Grumpier Old Men</td>\n",
              "      <td>Comedy|Romance</td>\n",
              "      <td>1995.0</td>\n",
              "      <td>American</td>\n",
              "      <td>Howard Deutch</td>\n",
              "      <td>Jack Lemmon, Walter Matthau, Ann-Margret, Soph...</td>\n",
              "      <td>comedy</td>\n",
              "      <td>https://en.wikipedia.org/wiki/Grumpier_Old_Men</td>\n",
              "      <td>The feud between Max (Walter Matthau) and John...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>Waiting to Exhale</td>\n",
              "      <td>Comedy|Drama|Romance</td>\n",
              "      <td>1995.0</td>\n",
              "      <td>American</td>\n",
              "      <td>Forest Whitaker</td>\n",
              "      <td>Whitney Houston, Angela Bassett, Loretta Devin...</td>\n",
              "      <td>drama</td>\n",
              "      <td>https://en.wikipedia.org/wiki/Waiting_to_Exhale</td>\n",
              "      <td>\"Friends are the People who let you be yoursel...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>Father of the Bride Part II</td>\n",
              "      <td>Comedy</td>\n",
              "      <td>1995.0</td>\n",
              "      <td>American</td>\n",
              "      <td>Charles Shyer</td>\n",
              "      <td>Steve Martin, Diane Keaton, Martin Short, Kimb...</td>\n",
              "      <td>comedy</td>\n",
              "      <td>https://en.wikipedia.org/wiki/Father_of_the_Br...</td>\n",
              "      <td>The film begins five years after the events of...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11988</th>\n",
              "      <td>29222</td>\n",
              "      <td>131152</td>\n",
              "      <td>The Fat Spy</td>\n",
              "      <td>Comedy</td>\n",
              "      <td>1966.0</td>\n",
              "      <td>American</td>\n",
              "      <td>Joseph Cates</td>\n",
              "      <td>Phyllis Diller, Jack E. Leonard, Brian Donlevy...</td>\n",
              "      <td>comedy</td>\n",
              "      <td>https://en.wikipedia.org/wiki/The_Fat_Spy</td>\n",
              "      <td>A mostly-deserted island, which is believed to...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11989</th>\n",
              "      <td>29230</td>\n",
              "      <td>131168</td>\n",
              "      <td>Phoenix</td>\n",
              "      <td>Drama</td>\n",
              "      <td>1998.0</td>\n",
              "      <td>American</td>\n",
              "      <td>Danny Cannon</td>\n",
              "      <td>Ray Liotta, Anjelica Huston, Anthony LaPaglia,...</td>\n",
              "      <td>crime</td>\n",
              "      <td>https://en.wikipedia.org/wiki/Phoenix_(1998_film)</td>\n",
              "      <td>In Phoenix, Arizona, Harry Collins is a cop wh...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11990</th>\n",
              "      <td>29235</td>\n",
              "      <td>131180</td>\n",
              "      <td>Dead Rising: Watchtower</td>\n",
              "      <td>Action|Horror|Thriller</td>\n",
              "      <td>2015.0</td>\n",
              "      <td>Canadian</td>\n",
              "      <td>Zach Lipovsky</td>\n",
              "      <td>Jesse Metcalfe, Dennis Haysbert, Virginia Madsen</td>\n",
              "      <td>zombie horror</td>\n",
              "      <td>https://en.wikipedia.org/wiki/Dead_Rising:_Wat...</td>\n",
              "      <td>Set between the events of Dead Rising 2 and De...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11991</th>\n",
              "      <td>29237</td>\n",
              "      <td>131237</td>\n",
              "      <td>What Men Talk About</td>\n",
              "      <td>Comedy</td>\n",
              "      <td>2010.0</td>\n",
              "      <td>Russian</td>\n",
              "      <td>Dmitry Dyashchenko</td>\n",
              "      <td>NaN</td>\n",
              "      <td>comedy</td>\n",
              "      <td>https://en.wikipedia.org/wiki/What_Men_Talk_About</td>\n",
              "      <td>What Men Talk About? Of course, women. But als...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11992</th>\n",
              "      <td>29246</td>\n",
              "      <td>131258</td>\n",
              "      <td>The Pirates</td>\n",
              "      <td>Adventure</td>\n",
              "      <td>2014.0</td>\n",
              "      <td>South_Korean</td>\n",
              "      <td>Lee Seok-hoon</td>\n",
              "      <td>Kim Nam-gil, Son Ye-jin</td>\n",
              "      <td>unknown</td>\n",
              "      <td>https://en.wikipedia.org/wiki/The_Pirates_(201...</td>\n",
              "      <td>On the eve of the founding of the Joseon Dynas...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>11993 rows × 11 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       index  ...                                               Plot\n",
              "0          0  ...  In a world where toys are living things who pr...\n",
              "1          1  ...  In 1869, near Brantford, New Hampshire, two br...\n",
              "2          2  ...  The feud between Max (Walter Matthau) and John...\n",
              "3          3  ...  \"Friends are the People who let you be yoursel...\n",
              "4          4  ...  The film begins five years after the events of...\n",
              "...      ...  ...                                                ...\n",
              "11988  29222  ...  A mostly-deserted island, which is believed to...\n",
              "11989  29230  ...  In Phoenix, Arizona, Harry Collins is a cop wh...\n",
              "11990  29235  ...  Set between the events of Dead Rising 2 and De...\n",
              "11991  29237  ...  What Men Talk About? Of course, women. But als...\n",
              "11992  29246  ...  On the eve of the founding of the Joseon Dynas...\n",
              "\n",
              "[11993 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IgkL6Z01xsL8",
        "outputId": "2142fd8c-c4ae-4414-e54c-fe6da60ffb2f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        "reviews"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>critic_name</th>\n",
              "      <th>media</th>\n",
              "      <th>title</th>\n",
              "      <th>review_date</th>\n",
              "      <th>individual_meta_score</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>M. E. Russell</td>\n",
              "      <td>Portland Oregonian</td>\n",
              "      <td>Hustle &amp; Flow</td>\n",
              "      <td>NaN</td>\n",
              "      <td>100</td>\n",
              "      <td>The writing, acting and filmmaking make Hustle...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Owen Gleiberman</td>\n",
              "      <td>Entertainment Weekly</td>\n",
              "      <td>Hustle &amp; Flow</td>\n",
              "      <td>NaN</td>\n",
              "      <td>91</td>\n",
              "      <td>The home-studio recording sequences in Hustle ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Ann Hornaday</td>\n",
              "      <td>Washington Post</td>\n",
              "      <td>Hustle &amp; Flow</td>\n",
              "      <td>NaN</td>\n",
              "      <td>90</td>\n",
              "      <td>The performances are accomplished, but the rea...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Stephanie Zacharek</td>\n",
              "      <td>Salon</td>\n",
              "      <td>Hustle &amp; Flow</td>\n",
              "      <td>NaN</td>\n",
              "      <td>90</td>\n",
              "      <td>In a world of movies that try far too hard to ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Jami Bernard</td>\n",
              "      <td>New York Daily News</td>\n",
              "      <td>Hustle &amp; Flow</td>\n",
              "      <td>NaN</td>\n",
              "      <td>88</td>\n",
              "      <td>The feel-good movie of the summer. And the son...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>246950</th>\n",
              "      <td>John Patterson</td>\n",
              "      <td>L.A. Weekly</td>\n",
              "      <td>The Quiet American</td>\n",
              "      <td>NaN</td>\n",
              "      <td>70</td>\n",
              "      <td>Noyce has made a good-looking, intelligent sta...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>246951</th>\n",
              "      <td>Rick Groen</td>\n",
              "      <td>The Globe and Mail (Toronto)</td>\n",
              "      <td>The Quiet American</td>\n",
              "      <td>NaN</td>\n",
              "      <td>63</td>\n",
              "      <td>The result is a rarity on the modern screen --...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>246952</th>\n",
              "      <td>Jonathan Foreman</td>\n",
              "      <td>New York Post</td>\n",
              "      <td>The Quiet American</td>\n",
              "      <td>NaN</td>\n",
              "      <td>63</td>\n",
              "      <td>It's a shame that, on top of everything else, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>246953</th>\n",
              "      <td>Jami Bernard</td>\n",
              "      <td>New York Daily News</td>\n",
              "      <td>The Quiet American</td>\n",
              "      <td>NaN</td>\n",
              "      <td>50</td>\n",
              "      <td>The movie adds nothing to the political dialog...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>246954</th>\n",
              "      <td>Stanley Kauffmann</td>\n",
              "      <td>The New Republic</td>\n",
              "      <td>The Quiet American</td>\n",
              "      <td>NaN</td>\n",
              "      <td>30</td>\n",
              "      <td>As is frequently the case when there is public...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>246955 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "               critic_name  ...                                               text\n",
              "0            M. E. Russell  ...  The writing, acting and filmmaking make Hustle...\n",
              "1          Owen Gleiberman  ...  The home-studio recording sequences in Hustle ...\n",
              "2             Ann Hornaday  ...  The performances are accomplished, but the rea...\n",
              "3       Stephanie Zacharek  ...  In a world of movies that try far too hard to ...\n",
              "4             Jami Bernard  ...  The feel-good movie of the summer. And the son...\n",
              "...                    ...  ...                                                ...\n",
              "246950      John Patterson  ...  Noyce has made a good-looking, intelligent sta...\n",
              "246951          Rick Groen  ...  The result is a rarity on the modern screen --...\n",
              "246952    Jonathan Foreman  ...  It's a shame that, on top of everything else, ...\n",
              "246953        Jami Bernard  ...  The movie adds nothing to the political dialog...\n",
              "246954   Stanley Kauffmann  ...  As is frequently the case when there is public...\n",
              "\n",
              "[246955 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cw7Sx1mixsde"
      },
      "source": [
        "reviews = reviews.astype(str) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xg12W3brxspR"
      },
      "source": [
        "reviews = reviews.groupby(\"title\")['text'].apply(' '.join).reset_index()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zditRNInxsgc",
        "outputId": "5bcac8af-058e-47d3-c5a0-d05f13e5a1fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        "reviews"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>!Women Art Revolution</td>\n",
              "      <td>These interviews form the backbone of !W.A.R.,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>#Horror</td>\n",
              "      <td>Not every gamble works: The girls' intrusive B...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>$9.99</td>\n",
              "      <td>Using the droll, wise stories of Etgar Keret a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>$pent</td>\n",
              "      <td>Has a warm and intimate feel that helps push i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>'71</td>\n",
              "      <td>Swift and exciting, with no taste for the usua...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12024</th>\n",
              "      <td>xXx: State of the Union</td>\n",
              "      <td>This is a B movie rooted in gut-level stirring...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12025</th>\n",
              "      <td>À Tout de Suite (Right Now)</td>\n",
              "      <td>It's hard to imagine many films surpassing or ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12026</th>\n",
              "      <td>À cause d'un garçon</td>\n",
              "      <td>While Cazeneuve's story is about gay love, it ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12027</th>\n",
              "      <td>Æon Flux</td>\n",
              "      <td>It's all so geekily gorgeous, it hardly matter...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12028</th>\n",
              "      <td>Ça commence aujourd'hui</td>\n",
              "      <td>nan Although there is real pain and suffering ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>12029 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                             title                                               text\n",
              "0            !Women Art Revolution  These interviews form the backbone of !W.A.R.,...\n",
              "1                          #Horror  Not every gamble works: The girls' intrusive B...\n",
              "2                           $9.99   Using the droll, wise stories of Etgar Keret a...\n",
              "3                            $pent  Has a warm and intimate feel that helps push i...\n",
              "4                              '71  Swift and exciting, with no taste for the usua...\n",
              "...                            ...                                                ...\n",
              "12024      xXx: State of the Union  This is a B movie rooted in gut-level stirring...\n",
              "12025  À Tout de Suite (Right Now)  It's hard to imagine many films surpassing or ...\n",
              "12026          À cause d'un garçon  While Cazeneuve's story is about gay love, it ...\n",
              "12027                     Æon Flux  It's all so geekily gorgeous, it hardly matter...\n",
              "12028      Ça commence aujourd'hui  nan Although there is real pain and suffering ...\n",
              "\n",
              "[12029 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hGyZ8jsGxsQV"
      },
      "source": [
        "df = pd.merge(df, reviews ,  how='left', left_on='title', right_on='title')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VkLt-RPLxsET"
      },
      "source": [
        "df = df[df['text'].notna()]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gOCfTMNKx1j6",
        "outputId": "4d76233f-4311-429d-da81-50c55b126448",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>movieId</th>\n",
              "      <th>title</th>\n",
              "      <th>genres</th>\n",
              "      <th>Release Year</th>\n",
              "      <th>Origin/Ethnicity</th>\n",
              "      <th>Director</th>\n",
              "      <th>Cast</th>\n",
              "      <th>Genre</th>\n",
              "      <th>Wiki Page</th>\n",
              "      <th>Plot</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>Toy Story</td>\n",
              "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
              "      <td>1995.0</td>\n",
              "      <td>American</td>\n",
              "      <td>John Lasseter</td>\n",
              "      <td>Tim Allen, Tom Hanks (voices)</td>\n",
              "      <td>animated film</td>\n",
              "      <td>https://en.wikipedia.org/wiki/Toy_Story</td>\n",
              "      <td>In a world where toys are living things who pr...</td>\n",
              "      <td>With \"instant classic\" written all over it, To...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>Jumanji</td>\n",
              "      <td>Adventure|Children|Fantasy</td>\n",
              "      <td>1995.0</td>\n",
              "      <td>American</td>\n",
              "      <td>Joe Johnston</td>\n",
              "      <td>Robin Williams, Bonnie Hunt, Kirsten Dunst, Br...</td>\n",
              "      <td>family, fantasy</td>\n",
              "      <td>https://en.wikipedia.org/wiki/Jumanji_(film)</td>\n",
              "      <td>In 1869, near Brantford, New Hampshire, two br...</td>\n",
              "      <td>The result is a thrill ride with enough plunge...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>Grumpier Old Men</td>\n",
              "      <td>Comedy|Romance</td>\n",
              "      <td>1995.0</td>\n",
              "      <td>American</td>\n",
              "      <td>Howard Deutch</td>\n",
              "      <td>Jack Lemmon, Walter Matthau, Ann-Margret, Soph...</td>\n",
              "      <td>comedy</td>\n",
              "      <td>https://en.wikipedia.org/wiki/Grumpier_Old_Men</td>\n",
              "      <td>The feud between Max (Walter Matthau) and John...</td>\n",
              "      <td>Grumpier is a welcome continuation that leaves...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>Father of the Bride Part II</td>\n",
              "      <td>Comedy</td>\n",
              "      <td>1995.0</td>\n",
              "      <td>American</td>\n",
              "      <td>Charles Shyer</td>\n",
              "      <td>Steve Martin, Diane Keaton, Martin Short, Kimb...</td>\n",
              "      <td>comedy</td>\n",
              "      <td>https://en.wikipedia.org/wiki/Father_of_the_Br...</td>\n",
              "      <td>The film begins five years after the events of...</td>\n",
              "      <td>nan What Meyers and Shyer have accomplished is...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>Heat</td>\n",
              "      <td>Action|Crime|Thriller</td>\n",
              "      <td>1972.0</td>\n",
              "      <td>American</td>\n",
              "      <td>Paul Morrissey</td>\n",
              "      <td>Joe Dallesandro, Sylvia Miles</td>\n",
              "      <td>drama</td>\n",
              "      <td>https://en.wikipedia.org/wiki/Heat_(1972_film)</td>\n",
              "      <td>Joey Davis is an unemployed former child star ...</td>\n",
              "      <td>Stunningly made and incisively acted by a larg...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11970</th>\n",
              "      <td>29116</td>\n",
              "      <td>130622</td>\n",
              "      <td>The Circle</td>\n",
              "      <td>Documentary|Drama</td>\n",
              "      <td>1925.0</td>\n",
              "      <td>American</td>\n",
              "      <td>Frank Borzage</td>\n",
              "      <td>Eleanor Boardman, Malcolm McGregor</td>\n",
              "      <td>romance drama</td>\n",
              "      <td>https://en.wikipedia.org/wiki/The_Circle_(1925...</td>\n",
              "      <td>In the 1890s, young Lady Catherine (Joan Crawf...</td>\n",
              "      <td>The Circle is very much a plea for the preserv...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11971</th>\n",
              "      <td>29117</td>\n",
              "      <td>130622</td>\n",
              "      <td>The Circle</td>\n",
              "      <td>Documentary|Drama</td>\n",
              "      <td>2017.0</td>\n",
              "      <td>American</td>\n",
              "      <td>James Ponsoldt</td>\n",
              "      <td>James Ponsoldt (director/screenplay); Tom Hank...</td>\n",
              "      <td>sci-fi, drama, thriller</td>\n",
              "      <td>https://en.wikipedia.org/wiki/The_Circle_(2017...</td>\n",
              "      <td>When her car breaks down, Mae Holland contacts...</td>\n",
              "      <td>The Circle is very much a plea for the preserv...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11978</th>\n",
              "      <td>29162</td>\n",
              "      <td>131013</td>\n",
              "      <td>Get Hard</td>\n",
              "      <td>Comedy</td>\n",
              "      <td>2015.0</td>\n",
              "      <td>American</td>\n",
              "      <td>Etan Cohen</td>\n",
              "      <td>Will Ferrell\\r\\nKevin Hart\\r\\nAlison Brie\\r\\nE...</td>\n",
              "      <td>comedy</td>\n",
              "      <td>https://en.wikipedia.org/wiki/Get_Hard</td>\n",
              "      <td>James King is an extremely wealthy hedge fund ...</td>\n",
              "      <td>It matches up two comic actors and instead of ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11987</th>\n",
              "      <td>29207</td>\n",
              "      <td>131122</td>\n",
              "      <td>Love Exposure</td>\n",
              "      <td>Action|Comedy|Drama|Romance</td>\n",
              "      <td>2008.0</td>\n",
              "      <td>Japanese</td>\n",
              "      <td>Shion Sono</td>\n",
              "      <td>Atsuro Watabe, Itsuji Itao, Mami Nakamura, Hik...</td>\n",
              "      <td>romance, comedy, drama, art house &amp; internatio...</td>\n",
              "      <td>https://en.wikipedia.org/wiki/Love_Exposure</td>\n",
              "      <td>The story follows Yū Honda (Takahiro Nishijima...</td>\n",
              "      <td>The movie’s invigorating discourse on sin, lus...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11989</th>\n",
              "      <td>29230</td>\n",
              "      <td>131168</td>\n",
              "      <td>Phoenix</td>\n",
              "      <td>Drama</td>\n",
              "      <td>1998.0</td>\n",
              "      <td>American</td>\n",
              "      <td>Danny Cannon</td>\n",
              "      <td>Ray Liotta, Anjelica Huston, Anthony LaPaglia,...</td>\n",
              "      <td>crime</td>\n",
              "      <td>https://en.wikipedia.org/wiki/Phoenix_(1998_film)</td>\n",
              "      <td>In Phoenix, Arizona, Harry Collins is a cop wh...</td>\n",
              "      <td>There is intrigue. There is suspense. Guilt - ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5962 rows × 12 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       index  ...                                               text\n",
              "0          0  ...  With \"instant classic\" written all over it, To...\n",
              "1          1  ...  The result is a thrill ride with enough plunge...\n",
              "2          2  ...  Grumpier is a welcome continuation that leaves...\n",
              "4          4  ...  nan What Meyers and Shyer have accomplished is...\n",
              "5          5  ...  Stunningly made and incisively acted by a larg...\n",
              "...      ...  ...                                                ...\n",
              "11970  29116  ...  The Circle is very much a plea for the preserv...\n",
              "11971  29117  ...  The Circle is very much a plea for the preserv...\n",
              "11978  29162  ...  It matches up two comic actors and instead of ...\n",
              "11987  29207  ...  The movie’s invigorating discourse on sin, lus...\n",
              "11989  29230  ...  There is intrigue. There is suspense. Guilt - ...\n",
              "\n",
              "[5962 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "itiH7Jwvx3Ob"
      },
      "source": [
        " df.drop(df.columns.difference(['Plot','title', 'text', 'movieId']), 1, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kdH9Y-8cx4ll"
      },
      "source": [
        "df = df.reset_index()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W2qb74H6x5o9"
      },
      "source": [
        "df = df.drop(['index'], axis = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jiFfEi9Xx6NY",
        "outputId": "0b3a1bb9-b954-4ba6-c2fb-76b2cd22f096",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>movieId</th>\n",
              "      <th>title</th>\n",
              "      <th>Plot</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Toy Story</td>\n",
              "      <td>In a world where toys are living things who pr...</td>\n",
              "      <td>With \"instant classic\" written all over it, To...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>Jumanji</td>\n",
              "      <td>In 1869, near Brantford, New Hampshire, two br...</td>\n",
              "      <td>The result is a thrill ride with enough plunge...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>Grumpier Old Men</td>\n",
              "      <td>The feud between Max (Walter Matthau) and John...</td>\n",
              "      <td>Grumpier is a welcome continuation that leaves...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5</td>\n",
              "      <td>Father of the Bride Part II</td>\n",
              "      <td>The film begins five years after the events of...</td>\n",
              "      <td>nan What Meyers and Shyer have accomplished is...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6</td>\n",
              "      <td>Heat</td>\n",
              "      <td>Joey Davis is an unemployed former child star ...</td>\n",
              "      <td>Stunningly made and incisively acted by a larg...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   movieId  ...                                               text\n",
              "0        1  ...  With \"instant classic\" written all over it, To...\n",
              "1        2  ...  The result is a thrill ride with enough plunge...\n",
              "2        3  ...  Grumpier is a welcome continuation that leaves...\n",
              "3        5  ...  nan What Meyers and Shyer have accomplished is...\n",
              "4        6  ...  Stunningly made and incisively acted by a larg...\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wmk2k2DWx7jj"
      },
      "source": [
        "genome = pd.merge(genome_scores, genome_tags ,  how='left', left_on='tagId', right_on='tagId')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gh3b0724x7up",
        "outputId": "6693f94b-e630-49c3-e82d-e1886ba89ab8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        "genome"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>movieId</th>\n",
              "      <th>tagId</th>\n",
              "      <th>relevance</th>\n",
              "      <th>tag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.02500</td>\n",
              "      <td>007</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0.02500</td>\n",
              "      <td>007 (series)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0.05775</td>\n",
              "      <td>18th century</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>0.09675</td>\n",
              "      <td>1920s</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>0.14675</td>\n",
              "      <td>1930s</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11709763</th>\n",
              "      <td>131170</td>\n",
              "      <td>1124</td>\n",
              "      <td>0.58775</td>\n",
              "      <td>writing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11709764</th>\n",
              "      <td>131170</td>\n",
              "      <td>1125</td>\n",
              "      <td>0.01075</td>\n",
              "      <td>wuxia</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11709765</th>\n",
              "      <td>131170</td>\n",
              "      <td>1126</td>\n",
              "      <td>0.01575</td>\n",
              "      <td>wwii</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11709766</th>\n",
              "      <td>131170</td>\n",
              "      <td>1127</td>\n",
              "      <td>0.11450</td>\n",
              "      <td>zombie</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11709767</th>\n",
              "      <td>131170</td>\n",
              "      <td>1128</td>\n",
              "      <td>0.02175</td>\n",
              "      <td>zombies</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>11709768 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          movieId  tagId  relevance           tag\n",
              "0               1      1    0.02500           007\n",
              "1               1      2    0.02500  007 (series)\n",
              "2               1      3    0.05775  18th century\n",
              "3               1      4    0.09675         1920s\n",
              "4               1      5    0.14675         1930s\n",
              "...           ...    ...        ...           ...\n",
              "11709763   131170   1124    0.58775       writing\n",
              "11709764   131170   1125    0.01075         wuxia\n",
              "11709765   131170   1126    0.01575          wwii\n",
              "11709766   131170   1127    0.11450        zombie\n",
              "11709767   131170   1128    0.02175       zombies\n",
              "\n",
              "[11709768 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9DnJyi0dx7yB"
      },
      "source": [
        "df = pd.merge(df, genome ,  how='left', left_on='movieId', right_on='movieId')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mXGd4bGBx7ov",
        "outputId": "1d2e7cf0-5e40-495e-997c-6b9c86921613",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>movieId</th>\n",
              "      <th>title</th>\n",
              "      <th>Plot</th>\n",
              "      <th>text</th>\n",
              "      <th>tagId</th>\n",
              "      <th>relevance</th>\n",
              "      <th>tag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Toy Story</td>\n",
              "      <td>In a world where toys are living things who pr...</td>\n",
              "      <td>With \"instant classic\" written all over it, To...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.02500</td>\n",
              "      <td>007</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Toy Story</td>\n",
              "      <td>In a world where toys are living things who pr...</td>\n",
              "      <td>With \"instant classic\" written all over it, To...</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.02500</td>\n",
              "      <td>007 (series)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>Toy Story</td>\n",
              "      <td>In a world where toys are living things who pr...</td>\n",
              "      <td>With \"instant classic\" written all over it, To...</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.05775</td>\n",
              "      <td>18th century</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>Toy Story</td>\n",
              "      <td>In a world where toys are living things who pr...</td>\n",
              "      <td>With \"instant classic\" written all over it, To...</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.09675</td>\n",
              "      <td>1920s</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>Toy Story</td>\n",
              "      <td>In a world where toys are living things who pr...</td>\n",
              "      <td>With \"instant classic\" written all over it, To...</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.14675</td>\n",
              "      <td>1930s</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5146204</th>\n",
              "      <td>131168</td>\n",
              "      <td>Phoenix</td>\n",
              "      <td>In Phoenix, Arizona, Harry Collins is a cop wh...</td>\n",
              "      <td>There is intrigue. There is suspense. Guilt - ...</td>\n",
              "      <td>1124.0</td>\n",
              "      <td>0.03225</td>\n",
              "      <td>writing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5146205</th>\n",
              "      <td>131168</td>\n",
              "      <td>Phoenix</td>\n",
              "      <td>In Phoenix, Arizona, Harry Collins is a cop wh...</td>\n",
              "      <td>There is intrigue. There is suspense. Guilt - ...</td>\n",
              "      <td>1125.0</td>\n",
              "      <td>0.04800</td>\n",
              "      <td>wuxia</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5146206</th>\n",
              "      <td>131168</td>\n",
              "      <td>Phoenix</td>\n",
              "      <td>In Phoenix, Arizona, Harry Collins is a cop wh...</td>\n",
              "      <td>There is intrigue. There is suspense. Guilt - ...</td>\n",
              "      <td>1126.0</td>\n",
              "      <td>0.51925</td>\n",
              "      <td>wwii</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5146207</th>\n",
              "      <td>131168</td>\n",
              "      <td>Phoenix</td>\n",
              "      <td>In Phoenix, Arizona, Harry Collins is a cop wh...</td>\n",
              "      <td>There is intrigue. There is suspense. Guilt - ...</td>\n",
              "      <td>1127.0</td>\n",
              "      <td>0.06700</td>\n",
              "      <td>zombie</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5146208</th>\n",
              "      <td>131168</td>\n",
              "      <td>Phoenix</td>\n",
              "      <td>In Phoenix, Arizona, Harry Collins is a cop wh...</td>\n",
              "      <td>There is intrigue. There is suspense. Guilt - ...</td>\n",
              "      <td>1128.0</td>\n",
              "      <td>0.01725</td>\n",
              "      <td>zombies</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5146209 rows × 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         movieId      title  ... relevance           tag\n",
              "0              1  Toy Story  ...   0.02500           007\n",
              "1              1  Toy Story  ...   0.02500  007 (series)\n",
              "2              1  Toy Story  ...   0.05775  18th century\n",
              "3              1  Toy Story  ...   0.09675         1920s\n",
              "4              1  Toy Story  ...   0.14675         1930s\n",
              "...          ...        ...  ...       ...           ...\n",
              "5146204   131168    Phoenix  ...   0.03225       writing\n",
              "5146205   131168    Phoenix  ...   0.04800         wuxia\n",
              "5146206   131168    Phoenix  ...   0.51925          wwii\n",
              "5146207   131168    Phoenix  ...   0.06700        zombie\n",
              "5146208   131168    Phoenix  ...   0.01725       zombies\n",
              "\n",
              "[5146209 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gh0lB6qPx7bM"
      },
      "source": [
        "df = df[df['relevance'].notna()]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5kva7CzLzclR"
      },
      "source": [
        "df = df[df['tag'].notna()]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ocskPV3zhFl"
      },
      "source": [
        "df = df[df['Plot'].notna()]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IHf5pof5yKI9"
      },
      "source": [
        "df = df.reset_index()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QrFRWpgUyKN7",
        "outputId": "1752c544-c2eb-49cf-c4c5-01e9e6197ef9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>movieId</th>\n",
              "      <th>title</th>\n",
              "      <th>Plot</th>\n",
              "      <th>text</th>\n",
              "      <th>tagId</th>\n",
              "      <th>relevance</th>\n",
              "      <th>tag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>Toy Story</td>\n",
              "      <td>In a world where toys are living things who pr...</td>\n",
              "      <td>With \"instant classic\" written all over it, To...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.02500</td>\n",
              "      <td>007</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Toy Story</td>\n",
              "      <td>In a world where toys are living things who pr...</td>\n",
              "      <td>With \"instant classic\" written all over it, To...</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.02500</td>\n",
              "      <td>007 (series)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>Toy Story</td>\n",
              "      <td>In a world where toys are living things who pr...</td>\n",
              "      <td>With \"instant classic\" written all over it, To...</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.05775</td>\n",
              "      <td>18th century</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>Toy Story</td>\n",
              "      <td>In a world where toys are living things who pr...</td>\n",
              "      <td>With \"instant classic\" written all over it, To...</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.09675</td>\n",
              "      <td>1920s</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>Toy Story</td>\n",
              "      <td>In a world where toys are living things who pr...</td>\n",
              "      <td>With \"instant classic\" written all over it, To...</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.14675</td>\n",
              "      <td>1930s</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5144803</th>\n",
              "      <td>5146204</td>\n",
              "      <td>131168</td>\n",
              "      <td>Phoenix</td>\n",
              "      <td>In Phoenix, Arizona, Harry Collins is a cop wh...</td>\n",
              "      <td>There is intrigue. There is suspense. Guilt - ...</td>\n",
              "      <td>1124.0</td>\n",
              "      <td>0.03225</td>\n",
              "      <td>writing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5144804</th>\n",
              "      <td>5146205</td>\n",
              "      <td>131168</td>\n",
              "      <td>Phoenix</td>\n",
              "      <td>In Phoenix, Arizona, Harry Collins is a cop wh...</td>\n",
              "      <td>There is intrigue. There is suspense. Guilt - ...</td>\n",
              "      <td>1125.0</td>\n",
              "      <td>0.04800</td>\n",
              "      <td>wuxia</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5144805</th>\n",
              "      <td>5146206</td>\n",
              "      <td>131168</td>\n",
              "      <td>Phoenix</td>\n",
              "      <td>In Phoenix, Arizona, Harry Collins is a cop wh...</td>\n",
              "      <td>There is intrigue. There is suspense. Guilt - ...</td>\n",
              "      <td>1126.0</td>\n",
              "      <td>0.51925</td>\n",
              "      <td>wwii</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5144806</th>\n",
              "      <td>5146207</td>\n",
              "      <td>131168</td>\n",
              "      <td>Phoenix</td>\n",
              "      <td>In Phoenix, Arizona, Harry Collins is a cop wh...</td>\n",
              "      <td>There is intrigue. There is suspense. Guilt - ...</td>\n",
              "      <td>1127.0</td>\n",
              "      <td>0.06700</td>\n",
              "      <td>zombie</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5144807</th>\n",
              "      <td>5146208</td>\n",
              "      <td>131168</td>\n",
              "      <td>Phoenix</td>\n",
              "      <td>In Phoenix, Arizona, Harry Collins is a cop wh...</td>\n",
              "      <td>There is intrigue. There is suspense. Guilt - ...</td>\n",
              "      <td>1128.0</td>\n",
              "      <td>0.01725</td>\n",
              "      <td>zombies</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5144808 rows × 8 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           index  movieId      title  ...   tagId relevance           tag\n",
              "0              0        1  Toy Story  ...     1.0   0.02500           007\n",
              "1              1        1  Toy Story  ...     2.0   0.02500  007 (series)\n",
              "2              2        1  Toy Story  ...     3.0   0.05775  18th century\n",
              "3              3        1  Toy Story  ...     4.0   0.09675         1920s\n",
              "4              4        1  Toy Story  ...     5.0   0.14675         1930s\n",
              "...          ...      ...        ...  ...     ...       ...           ...\n",
              "5144803  5146204   131168    Phoenix  ...  1124.0   0.03225       writing\n",
              "5144804  5146205   131168    Phoenix  ...  1125.0   0.04800         wuxia\n",
              "5144805  5146206   131168    Phoenix  ...  1126.0   0.51925          wwii\n",
              "5144806  5146207   131168    Phoenix  ...  1127.0   0.06700        zombie\n",
              "5144807  5146208   131168    Phoenix  ...  1128.0   0.01725       zombies\n",
              "\n",
              "[5144808 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eQxGM4TVTovR"
      },
      "source": [
        "pivot=df.pivot_table(index='movieId',columns='tagId',values='relevance').fillna(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bhTa_D1Gpk-l",
        "outputId": "b95a9222-15de-4213-b51c-e9e73a1e4049",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 470
        }
      },
      "source": [
        "pivot"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>tagId</th>\n",
              "      <th>1.0</th>\n",
              "      <th>2.0</th>\n",
              "      <th>3.0</th>\n",
              "      <th>4.0</th>\n",
              "      <th>5.0</th>\n",
              "      <th>6.0</th>\n",
              "      <th>7.0</th>\n",
              "      <th>8.0</th>\n",
              "      <th>9.0</th>\n",
              "      <th>10.0</th>\n",
              "      <th>11.0</th>\n",
              "      <th>12.0</th>\n",
              "      <th>13.0</th>\n",
              "      <th>14.0</th>\n",
              "      <th>15.0</th>\n",
              "      <th>16.0</th>\n",
              "      <th>17.0</th>\n",
              "      <th>18.0</th>\n",
              "      <th>19.0</th>\n",
              "      <th>20.0</th>\n",
              "      <th>21.0</th>\n",
              "      <th>22.0</th>\n",
              "      <th>23.0</th>\n",
              "      <th>24.0</th>\n",
              "      <th>25.0</th>\n",
              "      <th>26.0</th>\n",
              "      <th>27.0</th>\n",
              "      <th>28.0</th>\n",
              "      <th>29.0</th>\n",
              "      <th>30.0</th>\n",
              "      <th>31.0</th>\n",
              "      <th>32.0</th>\n",
              "      <th>33.0</th>\n",
              "      <th>34.0</th>\n",
              "      <th>35.0</th>\n",
              "      <th>36.0</th>\n",
              "      <th>37.0</th>\n",
              "      <th>38.0</th>\n",
              "      <th>39.0</th>\n",
              "      <th>40.0</th>\n",
              "      <th>...</th>\n",
              "      <th>1089.0</th>\n",
              "      <th>1090.0</th>\n",
              "      <th>1091.0</th>\n",
              "      <th>1092.0</th>\n",
              "      <th>1093.0</th>\n",
              "      <th>1094.0</th>\n",
              "      <th>1095.0</th>\n",
              "      <th>1096.0</th>\n",
              "      <th>1097.0</th>\n",
              "      <th>1098.0</th>\n",
              "      <th>1099.0</th>\n",
              "      <th>1100.0</th>\n",
              "      <th>1101.0</th>\n",
              "      <th>1102.0</th>\n",
              "      <th>1103.0</th>\n",
              "      <th>1104.0</th>\n",
              "      <th>1105.0</th>\n",
              "      <th>1106.0</th>\n",
              "      <th>1107.0</th>\n",
              "      <th>1108.0</th>\n",
              "      <th>1109.0</th>\n",
              "      <th>1110.0</th>\n",
              "      <th>1111.0</th>\n",
              "      <th>1112.0</th>\n",
              "      <th>1113.0</th>\n",
              "      <th>1114.0</th>\n",
              "      <th>1115.0</th>\n",
              "      <th>1116.0</th>\n",
              "      <th>1117.0</th>\n",
              "      <th>1118.0</th>\n",
              "      <th>1119.0</th>\n",
              "      <th>1120.0</th>\n",
              "      <th>1121.0</th>\n",
              "      <th>1122.0</th>\n",
              "      <th>1123.0</th>\n",
              "      <th>1124.0</th>\n",
              "      <th>1125.0</th>\n",
              "      <th>1126.0</th>\n",
              "      <th>1127.0</th>\n",
              "      <th>1128.0</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>movieId</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.02500</td>\n",
              "      <td>0.02500</td>\n",
              "      <td>0.05775</td>\n",
              "      <td>0.09675</td>\n",
              "      <td>0.14675</td>\n",
              "      <td>0.21700</td>\n",
              "      <td>0.06700</td>\n",
              "      <td>0.26275</td>\n",
              "      <td>0.26200</td>\n",
              "      <td>0.03200</td>\n",
              "      <td>0.57700</td>\n",
              "      <td>0.11625</td>\n",
              "      <td>0.18800</td>\n",
              "      <td>0.00800</td>\n",
              "      <td>0.03675</td>\n",
              "      <td>0.28175</td>\n",
              "      <td>0.00700</td>\n",
              "      <td>0.11050</td>\n",
              "      <td>0.67050</td>\n",
              "      <td>0.18450</td>\n",
              "      <td>0.33025</td>\n",
              "      <td>0.28250</td>\n",
              "      <td>0.05700</td>\n",
              "      <td>0.01550</td>\n",
              "      <td>0.08500</td>\n",
              "      <td>0.08100</td>\n",
              "      <td>0.19500</td>\n",
              "      <td>0.07150</td>\n",
              "      <td>0.89200</td>\n",
              "      <td>0.67625</td>\n",
              "      <td>0.03875</td>\n",
              "      <td>0.22800</td>\n",
              "      <td>0.40200</td>\n",
              "      <td>0.03875</td>\n",
              "      <td>0.02675</td>\n",
              "      <td>0.33025</td>\n",
              "      <td>0.10100</td>\n",
              "      <td>0.01250</td>\n",
              "      <td>0.01850</td>\n",
              "      <td>0.01425</td>\n",
              "      <td>...</td>\n",
              "      <td>0.10850</td>\n",
              "      <td>0.60425</td>\n",
              "      <td>0.41050</td>\n",
              "      <td>0.44500</td>\n",
              "      <td>0.33725</td>\n",
              "      <td>0.02175</td>\n",
              "      <td>0.04075</td>\n",
              "      <td>0.06250</td>\n",
              "      <td>0.04375</td>\n",
              "      <td>0.10075</td>\n",
              "      <td>0.00475</td>\n",
              "      <td>0.19225</td>\n",
              "      <td>0.25850</td>\n",
              "      <td>0.00900</td>\n",
              "      <td>0.02775</td>\n",
              "      <td>0.29925</td>\n",
              "      <td>0.04675</td>\n",
              "      <td>0.01025</td>\n",
              "      <td>0.02725</td>\n",
              "      <td>0.73700</td>\n",
              "      <td>0.11200</td>\n",
              "      <td>0.05125</td>\n",
              "      <td>0.04375</td>\n",
              "      <td>0.05350</td>\n",
              "      <td>0.12575</td>\n",
              "      <td>0.77675</td>\n",
              "      <td>0.14500</td>\n",
              "      <td>0.11275</td>\n",
              "      <td>0.04200</td>\n",
              "      <td>0.10250</td>\n",
              "      <td>0.03950</td>\n",
              "      <td>0.01800</td>\n",
              "      <td>0.04575</td>\n",
              "      <td>0.03275</td>\n",
              "      <td>0.12500</td>\n",
              "      <td>0.04150</td>\n",
              "      <td>0.01925</td>\n",
              "      <td>0.03625</td>\n",
              "      <td>0.07775</td>\n",
              "      <td>0.02300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.03975</td>\n",
              "      <td>0.04375</td>\n",
              "      <td>0.03775</td>\n",
              "      <td>0.04800</td>\n",
              "      <td>0.11025</td>\n",
              "      <td>0.07250</td>\n",
              "      <td>0.04775</td>\n",
              "      <td>0.10975</td>\n",
              "      <td>0.09925</td>\n",
              "      <td>0.02050</td>\n",
              "      <td>0.06775</td>\n",
              "      <td>0.08900</td>\n",
              "      <td>0.22575</td>\n",
              "      <td>0.00625</td>\n",
              "      <td>0.00300</td>\n",
              "      <td>0.03475</td>\n",
              "      <td>0.00950</td>\n",
              "      <td>0.18975</td>\n",
              "      <td>0.64600</td>\n",
              "      <td>0.40025</td>\n",
              "      <td>0.45100</td>\n",
              "      <td>0.60200</td>\n",
              "      <td>0.15100</td>\n",
              "      <td>0.28100</td>\n",
              "      <td>0.07600</td>\n",
              "      <td>0.14350</td>\n",
              "      <td>0.11675</td>\n",
              "      <td>0.04350</td>\n",
              "      <td>0.98100</td>\n",
              "      <td>0.10550</td>\n",
              "      <td>0.00825</td>\n",
              "      <td>0.06650</td>\n",
              "      <td>0.08575</td>\n",
              "      <td>0.05300</td>\n",
              "      <td>0.04525</td>\n",
              "      <td>0.14650</td>\n",
              "      <td>0.07750</td>\n",
              "      <td>0.02900</td>\n",
              "      <td>0.02275</td>\n",
              "      <td>0.02475</td>\n",
              "      <td>...</td>\n",
              "      <td>0.08925</td>\n",
              "      <td>0.32475</td>\n",
              "      <td>0.19125</td>\n",
              "      <td>0.32550</td>\n",
              "      <td>0.17675</td>\n",
              "      <td>0.02650</td>\n",
              "      <td>0.03500</td>\n",
              "      <td>0.04125</td>\n",
              "      <td>0.02775</td>\n",
              "      <td>0.04750</td>\n",
              "      <td>0.00575</td>\n",
              "      <td>0.04700</td>\n",
              "      <td>0.15700</td>\n",
              "      <td>0.01425</td>\n",
              "      <td>0.02400</td>\n",
              "      <td>0.31600</td>\n",
              "      <td>0.08850</td>\n",
              "      <td>0.02375</td>\n",
              "      <td>0.01300</td>\n",
              "      <td>0.24450</td>\n",
              "      <td>0.10075</td>\n",
              "      <td>0.03425</td>\n",
              "      <td>0.02475</td>\n",
              "      <td>0.26450</td>\n",
              "      <td>0.39025</td>\n",
              "      <td>0.18000</td>\n",
              "      <td>0.18725</td>\n",
              "      <td>0.14750</td>\n",
              "      <td>0.01500</td>\n",
              "      <td>0.05700</td>\n",
              "      <td>0.04175</td>\n",
              "      <td>0.01925</td>\n",
              "      <td>0.01725</td>\n",
              "      <td>0.02425</td>\n",
              "      <td>0.12550</td>\n",
              "      <td>0.02250</td>\n",
              "      <td>0.01550</td>\n",
              "      <td>0.01475</td>\n",
              "      <td>0.09025</td>\n",
              "      <td>0.01875</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.04350</td>\n",
              "      <td>0.05475</td>\n",
              "      <td>0.02800</td>\n",
              "      <td>0.07700</td>\n",
              "      <td>0.05400</td>\n",
              "      <td>0.06850</td>\n",
              "      <td>0.05600</td>\n",
              "      <td>0.18500</td>\n",
              "      <td>0.04925</td>\n",
              "      <td>0.02675</td>\n",
              "      <td>0.02225</td>\n",
              "      <td>0.07100</td>\n",
              "      <td>0.09050</td>\n",
              "      <td>0.00475</td>\n",
              "      <td>0.00250</td>\n",
              "      <td>0.02875</td>\n",
              "      <td>0.01175</td>\n",
              "      <td>0.10400</td>\n",
              "      <td>0.16475</td>\n",
              "      <td>0.17375</td>\n",
              "      <td>0.28000</td>\n",
              "      <td>0.20775</td>\n",
              "      <td>0.08675</td>\n",
              "      <td>0.01700</td>\n",
              "      <td>0.04250</td>\n",
              "      <td>0.08375</td>\n",
              "      <td>0.12225</td>\n",
              "      <td>0.10800</td>\n",
              "      <td>0.41200</td>\n",
              "      <td>0.09525</td>\n",
              "      <td>0.00900</td>\n",
              "      <td>0.04750</td>\n",
              "      <td>0.06475</td>\n",
              "      <td>0.05925</td>\n",
              "      <td>0.02600</td>\n",
              "      <td>0.20950</td>\n",
              "      <td>0.04375</td>\n",
              "      <td>0.02350</td>\n",
              "      <td>0.05675</td>\n",
              "      <td>0.01300</td>\n",
              "      <td>...</td>\n",
              "      <td>0.10525</td>\n",
              "      <td>0.11400</td>\n",
              "      <td>0.21250</td>\n",
              "      <td>0.16575</td>\n",
              "      <td>0.03550</td>\n",
              "      <td>0.02450</td>\n",
              "      <td>0.04925</td>\n",
              "      <td>0.03825</td>\n",
              "      <td>0.03400</td>\n",
              "      <td>0.07225</td>\n",
              "      <td>0.01125</td>\n",
              "      <td>0.03875</td>\n",
              "      <td>0.13875</td>\n",
              "      <td>0.41600</td>\n",
              "      <td>0.04175</td>\n",
              "      <td>0.16800</td>\n",
              "      <td>0.06175</td>\n",
              "      <td>0.02050</td>\n",
              "      <td>0.04275</td>\n",
              "      <td>0.15525</td>\n",
              "      <td>0.17250</td>\n",
              "      <td>0.04275</td>\n",
              "      <td>0.04450</td>\n",
              "      <td>0.02325</td>\n",
              "      <td>0.03375</td>\n",
              "      <td>0.19950</td>\n",
              "      <td>0.02825</td>\n",
              "      <td>0.37075</td>\n",
              "      <td>0.02625</td>\n",
              "      <td>0.07325</td>\n",
              "      <td>0.04150</td>\n",
              "      <td>0.02675</td>\n",
              "      <td>0.02775</td>\n",
              "      <td>0.03425</td>\n",
              "      <td>0.15550</td>\n",
              "      <td>0.03675</td>\n",
              "      <td>0.01700</td>\n",
              "      <td>0.01950</td>\n",
              "      <td>0.09700</td>\n",
              "      <td>0.01850</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.04200</td>\n",
              "      <td>0.05275</td>\n",
              "      <td>0.05925</td>\n",
              "      <td>0.03675</td>\n",
              "      <td>0.07525</td>\n",
              "      <td>0.12525</td>\n",
              "      <td>0.02850</td>\n",
              "      <td>0.08500</td>\n",
              "      <td>0.02950</td>\n",
              "      <td>0.02875</td>\n",
              "      <td>0.03125</td>\n",
              "      <td>0.06150</td>\n",
              "      <td>0.07175</td>\n",
              "      <td>0.00650</td>\n",
              "      <td>0.00225</td>\n",
              "      <td>0.02775</td>\n",
              "      <td>0.01425</td>\n",
              "      <td>0.16100</td>\n",
              "      <td>0.16350</td>\n",
              "      <td>0.22650</td>\n",
              "      <td>0.27575</td>\n",
              "      <td>0.21075</td>\n",
              "      <td>0.10275</td>\n",
              "      <td>0.02250</td>\n",
              "      <td>0.04150</td>\n",
              "      <td>0.05100</td>\n",
              "      <td>0.19200</td>\n",
              "      <td>0.17150</td>\n",
              "      <td>0.15375</td>\n",
              "      <td>0.12225</td>\n",
              "      <td>0.01000</td>\n",
              "      <td>0.04175</td>\n",
              "      <td>0.07950</td>\n",
              "      <td>0.04050</td>\n",
              "      <td>0.03175</td>\n",
              "      <td>0.07250</td>\n",
              "      <td>0.03400</td>\n",
              "      <td>0.01925</td>\n",
              "      <td>0.04200</td>\n",
              "      <td>0.00600</td>\n",
              "      <td>...</td>\n",
              "      <td>0.10825</td>\n",
              "      <td>0.14700</td>\n",
              "      <td>0.18750</td>\n",
              "      <td>0.22100</td>\n",
              "      <td>0.08950</td>\n",
              "      <td>0.01350</td>\n",
              "      <td>0.04075</td>\n",
              "      <td>0.03550</td>\n",
              "      <td>0.03075</td>\n",
              "      <td>0.06625</td>\n",
              "      <td>0.00775</td>\n",
              "      <td>0.03850</td>\n",
              "      <td>0.13150</td>\n",
              "      <td>0.80675</td>\n",
              "      <td>0.02650</td>\n",
              "      <td>0.26975</td>\n",
              "      <td>0.05575</td>\n",
              "      <td>0.02100</td>\n",
              "      <td>0.02175</td>\n",
              "      <td>0.20825</td>\n",
              "      <td>0.11850</td>\n",
              "      <td>0.14150</td>\n",
              "      <td>0.03875</td>\n",
              "      <td>0.03475</td>\n",
              "      <td>0.04675</td>\n",
              "      <td>0.12000</td>\n",
              "      <td>0.02925</td>\n",
              "      <td>0.48900</td>\n",
              "      <td>0.02150</td>\n",
              "      <td>0.07450</td>\n",
              "      <td>0.04250</td>\n",
              "      <td>0.02825</td>\n",
              "      <td>0.02150</td>\n",
              "      <td>0.02600</td>\n",
              "      <td>0.14275</td>\n",
              "      <td>0.02075</td>\n",
              "      <td>0.01650</td>\n",
              "      <td>0.01675</td>\n",
              "      <td>0.10750</td>\n",
              "      <td>0.01825</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.02825</td>\n",
              "      <td>0.02550</td>\n",
              "      <td>0.01850</td>\n",
              "      <td>0.04550</td>\n",
              "      <td>0.09575</td>\n",
              "      <td>0.05500</td>\n",
              "      <td>0.04400</td>\n",
              "      <td>0.24200</td>\n",
              "      <td>0.12850</td>\n",
              "      <td>0.02550</td>\n",
              "      <td>0.01550</td>\n",
              "      <td>0.04400</td>\n",
              "      <td>0.08000</td>\n",
              "      <td>0.00675</td>\n",
              "      <td>0.00350</td>\n",
              "      <td>0.03225</td>\n",
              "      <td>0.01250</td>\n",
              "      <td>0.18250</td>\n",
              "      <td>0.92475</td>\n",
              "      <td>0.60200</td>\n",
              "      <td>0.33625</td>\n",
              "      <td>0.24075</td>\n",
              "      <td>0.04125</td>\n",
              "      <td>0.01150</td>\n",
              "      <td>0.21450</td>\n",
              "      <td>0.06775</td>\n",
              "      <td>0.07200</td>\n",
              "      <td>0.26600</td>\n",
              "      <td>0.08050</td>\n",
              "      <td>0.25275</td>\n",
              "      <td>0.01850</td>\n",
              "      <td>0.03300</td>\n",
              "      <td>0.20750</td>\n",
              "      <td>0.00975</td>\n",
              "      <td>0.02025</td>\n",
              "      <td>0.07000</td>\n",
              "      <td>0.06700</td>\n",
              "      <td>0.02250</td>\n",
              "      <td>0.11575</td>\n",
              "      <td>0.00650</td>\n",
              "      <td>...</td>\n",
              "      <td>0.84025</td>\n",
              "      <td>0.35350</td>\n",
              "      <td>0.32900</td>\n",
              "      <td>0.40500</td>\n",
              "      <td>0.07050</td>\n",
              "      <td>0.02225</td>\n",
              "      <td>0.04600</td>\n",
              "      <td>0.04125</td>\n",
              "      <td>0.06275</td>\n",
              "      <td>0.06550</td>\n",
              "      <td>0.00775</td>\n",
              "      <td>0.05675</td>\n",
              "      <td>0.67900</td>\n",
              "      <td>0.02050</td>\n",
              "      <td>0.03050</td>\n",
              "      <td>0.22875</td>\n",
              "      <td>0.06900</td>\n",
              "      <td>0.01725</td>\n",
              "      <td>0.02875</td>\n",
              "      <td>0.08600</td>\n",
              "      <td>0.07000</td>\n",
              "      <td>0.10675</td>\n",
              "      <td>0.04675</td>\n",
              "      <td>0.00900</td>\n",
              "      <td>0.02550</td>\n",
              "      <td>0.40750</td>\n",
              "      <td>0.03375</td>\n",
              "      <td>0.10925</td>\n",
              "      <td>0.06375</td>\n",
              "      <td>0.18800</td>\n",
              "      <td>0.04900</td>\n",
              "      <td>0.01825</td>\n",
              "      <td>0.02075</td>\n",
              "      <td>0.06000</td>\n",
              "      <td>0.29975</td>\n",
              "      <td>0.15525</td>\n",
              "      <td>0.03525</td>\n",
              "      <td>0.01950</td>\n",
              "      <td>0.06650</td>\n",
              "      <td>0.01900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>130496</th>\n",
              "      <td>0.03275</td>\n",
              "      <td>0.03000</td>\n",
              "      <td>0.02400</td>\n",
              "      <td>0.02375</td>\n",
              "      <td>0.06400</td>\n",
              "      <td>0.03350</td>\n",
              "      <td>0.01350</td>\n",
              "      <td>0.11475</td>\n",
              "      <td>0.24425</td>\n",
              "      <td>0.01275</td>\n",
              "      <td>0.02850</td>\n",
              "      <td>0.04950</td>\n",
              "      <td>0.63375</td>\n",
              "      <td>0.01175</td>\n",
              "      <td>0.00750</td>\n",
              "      <td>0.08675</td>\n",
              "      <td>0.01175</td>\n",
              "      <td>0.62975</td>\n",
              "      <td>0.92775</td>\n",
              "      <td>0.52600</td>\n",
              "      <td>0.28825</td>\n",
              "      <td>0.17500</td>\n",
              "      <td>0.04750</td>\n",
              "      <td>0.03225</td>\n",
              "      <td>0.14425</td>\n",
              "      <td>0.17550</td>\n",
              "      <td>0.10100</td>\n",
              "      <td>0.03475</td>\n",
              "      <td>0.66275</td>\n",
              "      <td>0.16625</td>\n",
              "      <td>0.00975</td>\n",
              "      <td>0.03325</td>\n",
              "      <td>0.05575</td>\n",
              "      <td>0.03575</td>\n",
              "      <td>0.02525</td>\n",
              "      <td>0.05625</td>\n",
              "      <td>0.09625</td>\n",
              "      <td>0.07425</td>\n",
              "      <td>0.00800</td>\n",
              "      <td>0.00650</td>\n",
              "      <td>...</td>\n",
              "      <td>0.12475</td>\n",
              "      <td>0.31475</td>\n",
              "      <td>0.32100</td>\n",
              "      <td>0.16350</td>\n",
              "      <td>0.16975</td>\n",
              "      <td>0.00825</td>\n",
              "      <td>0.04925</td>\n",
              "      <td>0.03050</td>\n",
              "      <td>0.03750</td>\n",
              "      <td>0.03950</td>\n",
              "      <td>0.03300</td>\n",
              "      <td>0.02150</td>\n",
              "      <td>0.52075</td>\n",
              "      <td>0.01575</td>\n",
              "      <td>0.04225</td>\n",
              "      <td>0.17125</td>\n",
              "      <td>0.05475</td>\n",
              "      <td>0.02000</td>\n",
              "      <td>0.05050</td>\n",
              "      <td>0.18625</td>\n",
              "      <td>0.45200</td>\n",
              "      <td>0.04150</td>\n",
              "      <td>0.03700</td>\n",
              "      <td>0.02325</td>\n",
              "      <td>0.04950</td>\n",
              "      <td>0.18700</td>\n",
              "      <td>0.03150</td>\n",
              "      <td>0.11675</td>\n",
              "      <td>0.01800</td>\n",
              "      <td>0.04500</td>\n",
              "      <td>0.08700</td>\n",
              "      <td>0.03700</td>\n",
              "      <td>0.01300</td>\n",
              "      <td>0.03600</td>\n",
              "      <td>0.28125</td>\n",
              "      <td>0.06875</td>\n",
              "      <td>0.05100</td>\n",
              "      <td>0.00825</td>\n",
              "      <td>0.09050</td>\n",
              "      <td>0.01675</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>130520</th>\n",
              "      <td>0.05875</td>\n",
              "      <td>0.02325</td>\n",
              "      <td>0.02150</td>\n",
              "      <td>0.04425</td>\n",
              "      <td>0.05000</td>\n",
              "      <td>0.02925</td>\n",
              "      <td>0.01825</td>\n",
              "      <td>0.04650</td>\n",
              "      <td>0.02250</td>\n",
              "      <td>0.02600</td>\n",
              "      <td>0.51275</td>\n",
              "      <td>0.01500</td>\n",
              "      <td>0.05025</td>\n",
              "      <td>0.00875</td>\n",
              "      <td>0.01075</td>\n",
              "      <td>0.03925</td>\n",
              "      <td>0.01250</td>\n",
              "      <td>0.15050</td>\n",
              "      <td>0.14625</td>\n",
              "      <td>0.10775</td>\n",
              "      <td>0.33875</td>\n",
              "      <td>0.16875</td>\n",
              "      <td>0.14100</td>\n",
              "      <td>0.01600</td>\n",
              "      <td>0.06050</td>\n",
              "      <td>0.06100</td>\n",
              "      <td>0.21675</td>\n",
              "      <td>0.03600</td>\n",
              "      <td>0.58450</td>\n",
              "      <td>0.09650</td>\n",
              "      <td>0.00875</td>\n",
              "      <td>0.01900</td>\n",
              "      <td>0.03425</td>\n",
              "      <td>0.04300</td>\n",
              "      <td>0.01300</td>\n",
              "      <td>0.10050</td>\n",
              "      <td>0.02350</td>\n",
              "      <td>0.00550</td>\n",
              "      <td>0.00725</td>\n",
              "      <td>0.00650</td>\n",
              "      <td>...</td>\n",
              "      <td>0.05650</td>\n",
              "      <td>0.15050</td>\n",
              "      <td>0.60425</td>\n",
              "      <td>0.36725</td>\n",
              "      <td>0.24825</td>\n",
              "      <td>0.01200</td>\n",
              "      <td>0.03325</td>\n",
              "      <td>0.01200</td>\n",
              "      <td>0.03050</td>\n",
              "      <td>0.04525</td>\n",
              "      <td>0.04325</td>\n",
              "      <td>0.24575</td>\n",
              "      <td>0.16550</td>\n",
              "      <td>0.01075</td>\n",
              "      <td>0.04400</td>\n",
              "      <td>0.23675</td>\n",
              "      <td>0.03600</td>\n",
              "      <td>0.00975</td>\n",
              "      <td>0.01600</td>\n",
              "      <td>0.30675</td>\n",
              "      <td>0.04500</td>\n",
              "      <td>0.06075</td>\n",
              "      <td>0.02500</td>\n",
              "      <td>0.02525</td>\n",
              "      <td>0.04250</td>\n",
              "      <td>0.17800</td>\n",
              "      <td>0.02925</td>\n",
              "      <td>0.13550</td>\n",
              "      <td>0.01450</td>\n",
              "      <td>0.04800</td>\n",
              "      <td>0.04625</td>\n",
              "      <td>0.02275</td>\n",
              "      <td>0.01300</td>\n",
              "      <td>0.01750</td>\n",
              "      <td>0.26350</td>\n",
              "      <td>0.06500</td>\n",
              "      <td>0.01775</td>\n",
              "      <td>0.00850</td>\n",
              "      <td>0.06650</td>\n",
              "      <td>0.01575</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>130578</th>\n",
              "      <td>0.15400</td>\n",
              "      <td>0.04025</td>\n",
              "      <td>0.01975</td>\n",
              "      <td>0.01850</td>\n",
              "      <td>0.02850</td>\n",
              "      <td>0.02275</td>\n",
              "      <td>0.01000</td>\n",
              "      <td>0.03675</td>\n",
              "      <td>0.01025</td>\n",
              "      <td>0.01575</td>\n",
              "      <td>0.02750</td>\n",
              "      <td>0.01900</td>\n",
              "      <td>0.13775</td>\n",
              "      <td>0.01050</td>\n",
              "      <td>0.00125</td>\n",
              "      <td>0.00950</td>\n",
              "      <td>0.00475</td>\n",
              "      <td>0.17725</td>\n",
              "      <td>0.82350</td>\n",
              "      <td>0.44825</td>\n",
              "      <td>0.19775</td>\n",
              "      <td>0.08700</td>\n",
              "      <td>0.06025</td>\n",
              "      <td>0.02675</td>\n",
              "      <td>0.03950</td>\n",
              "      <td>0.03100</td>\n",
              "      <td>0.03950</td>\n",
              "      <td>0.04550</td>\n",
              "      <td>0.13475</td>\n",
              "      <td>0.02375</td>\n",
              "      <td>0.00375</td>\n",
              "      <td>0.02700</td>\n",
              "      <td>0.02075</td>\n",
              "      <td>0.18700</td>\n",
              "      <td>0.07950</td>\n",
              "      <td>0.15950</td>\n",
              "      <td>0.05225</td>\n",
              "      <td>0.01450</td>\n",
              "      <td>0.01350</td>\n",
              "      <td>0.00250</td>\n",
              "      <td>...</td>\n",
              "      <td>0.08200</td>\n",
              "      <td>0.07125</td>\n",
              "      <td>0.12200</td>\n",
              "      <td>0.15775</td>\n",
              "      <td>0.01775</td>\n",
              "      <td>0.01675</td>\n",
              "      <td>0.04050</td>\n",
              "      <td>0.01375</td>\n",
              "      <td>0.02950</td>\n",
              "      <td>0.05100</td>\n",
              "      <td>0.00350</td>\n",
              "      <td>0.01075</td>\n",
              "      <td>0.17225</td>\n",
              "      <td>0.01125</td>\n",
              "      <td>0.00700</td>\n",
              "      <td>0.11875</td>\n",
              "      <td>0.05475</td>\n",
              "      <td>0.01575</td>\n",
              "      <td>0.01000</td>\n",
              "      <td>0.08125</td>\n",
              "      <td>0.02650</td>\n",
              "      <td>0.05750</td>\n",
              "      <td>0.02825</td>\n",
              "      <td>0.01475</td>\n",
              "      <td>0.03350</td>\n",
              "      <td>0.04150</td>\n",
              "      <td>0.01200</td>\n",
              "      <td>0.07675</td>\n",
              "      <td>0.02125</td>\n",
              "      <td>0.11175</td>\n",
              "      <td>0.02875</td>\n",
              "      <td>0.01125</td>\n",
              "      <td>0.01250</td>\n",
              "      <td>0.02050</td>\n",
              "      <td>0.21000</td>\n",
              "      <td>0.02375</td>\n",
              "      <td>0.04225</td>\n",
              "      <td>0.00525</td>\n",
              "      <td>0.07575</td>\n",
              "      <td>0.01325</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>131013</th>\n",
              "      <td>0.04200</td>\n",
              "      <td>0.03175</td>\n",
              "      <td>0.01700</td>\n",
              "      <td>0.05600</td>\n",
              "      <td>0.05750</td>\n",
              "      <td>0.02675</td>\n",
              "      <td>0.01600</td>\n",
              "      <td>0.04200</td>\n",
              "      <td>0.02800</td>\n",
              "      <td>0.03725</td>\n",
              "      <td>0.02750</td>\n",
              "      <td>0.01375</td>\n",
              "      <td>0.06300</td>\n",
              "      <td>0.01125</td>\n",
              "      <td>0.00325</td>\n",
              "      <td>0.02500</td>\n",
              "      <td>0.01375</td>\n",
              "      <td>0.57025</td>\n",
              "      <td>0.19450</td>\n",
              "      <td>0.11000</td>\n",
              "      <td>0.30525</td>\n",
              "      <td>0.18475</td>\n",
              "      <td>0.11175</td>\n",
              "      <td>0.03100</td>\n",
              "      <td>0.06300</td>\n",
              "      <td>0.07275</td>\n",
              "      <td>0.11150</td>\n",
              "      <td>0.04025</td>\n",
              "      <td>0.12625</td>\n",
              "      <td>0.07000</td>\n",
              "      <td>0.00625</td>\n",
              "      <td>0.02600</td>\n",
              "      <td>0.02900</td>\n",
              "      <td>0.03925</td>\n",
              "      <td>0.02200</td>\n",
              "      <td>0.04100</td>\n",
              "      <td>0.03675</td>\n",
              "      <td>0.02650</td>\n",
              "      <td>0.01800</td>\n",
              "      <td>0.01175</td>\n",
              "      <td>...</td>\n",
              "      <td>0.06225</td>\n",
              "      <td>0.15950</td>\n",
              "      <td>0.28325</td>\n",
              "      <td>0.15725</td>\n",
              "      <td>0.10950</td>\n",
              "      <td>0.01800</td>\n",
              "      <td>0.01925</td>\n",
              "      <td>0.01650</td>\n",
              "      <td>0.03975</td>\n",
              "      <td>0.07450</td>\n",
              "      <td>0.08925</td>\n",
              "      <td>0.26675</td>\n",
              "      <td>0.19450</td>\n",
              "      <td>0.04050</td>\n",
              "      <td>0.35250</td>\n",
              "      <td>0.24050</td>\n",
              "      <td>0.07050</td>\n",
              "      <td>0.02200</td>\n",
              "      <td>0.01775</td>\n",
              "      <td>0.12150</td>\n",
              "      <td>0.04425</td>\n",
              "      <td>0.12700</td>\n",
              "      <td>0.02550</td>\n",
              "      <td>0.01775</td>\n",
              "      <td>0.03525</td>\n",
              "      <td>0.11325</td>\n",
              "      <td>0.03075</td>\n",
              "      <td>0.12050</td>\n",
              "      <td>0.06100</td>\n",
              "      <td>0.23650</td>\n",
              "      <td>0.06675</td>\n",
              "      <td>0.01300</td>\n",
              "      <td>0.01275</td>\n",
              "      <td>0.02275</td>\n",
              "      <td>0.20000</td>\n",
              "      <td>0.10750</td>\n",
              "      <td>0.02500</td>\n",
              "      <td>0.00950</td>\n",
              "      <td>0.07550</td>\n",
              "      <td>0.01625</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>131168</th>\n",
              "      <td>0.05975</td>\n",
              "      <td>0.10375</td>\n",
              "      <td>0.17850</td>\n",
              "      <td>0.14875</td>\n",
              "      <td>0.27750</td>\n",
              "      <td>0.16250</td>\n",
              "      <td>0.04125</td>\n",
              "      <td>0.25475</td>\n",
              "      <td>0.06900</td>\n",
              "      <td>0.15375</td>\n",
              "      <td>0.02075</td>\n",
              "      <td>0.01350</td>\n",
              "      <td>0.02900</td>\n",
              "      <td>0.10025</td>\n",
              "      <td>0.00300</td>\n",
              "      <td>0.02625</td>\n",
              "      <td>0.00925</td>\n",
              "      <td>0.23250</td>\n",
              "      <td>0.09675</td>\n",
              "      <td>0.07700</td>\n",
              "      <td>0.20100</td>\n",
              "      <td>0.35950</td>\n",
              "      <td>0.03925</td>\n",
              "      <td>0.01125</td>\n",
              "      <td>0.06225</td>\n",
              "      <td>0.09500</td>\n",
              "      <td>0.11050</td>\n",
              "      <td>0.33200</td>\n",
              "      <td>0.06300</td>\n",
              "      <td>0.34100</td>\n",
              "      <td>0.05475</td>\n",
              "      <td>0.12900</td>\n",
              "      <td>0.37000</td>\n",
              "      <td>0.02325</td>\n",
              "      <td>0.01925</td>\n",
              "      <td>0.02275</td>\n",
              "      <td>0.08725</td>\n",
              "      <td>0.01825</td>\n",
              "      <td>0.01450</td>\n",
              "      <td>0.00575</td>\n",
              "      <td>...</td>\n",
              "      <td>0.47425</td>\n",
              "      <td>0.24725</td>\n",
              "      <td>0.88100</td>\n",
              "      <td>0.22850</td>\n",
              "      <td>0.08725</td>\n",
              "      <td>0.00975</td>\n",
              "      <td>0.04400</td>\n",
              "      <td>0.13225</td>\n",
              "      <td>0.09725</td>\n",
              "      <td>0.38750</td>\n",
              "      <td>0.01775</td>\n",
              "      <td>0.02425</td>\n",
              "      <td>0.54325</td>\n",
              "      <td>0.04100</td>\n",
              "      <td>0.02825</td>\n",
              "      <td>0.21400</td>\n",
              "      <td>0.05000</td>\n",
              "      <td>0.00775</td>\n",
              "      <td>0.01925</td>\n",
              "      <td>0.11900</td>\n",
              "      <td>0.09275</td>\n",
              "      <td>0.14725</td>\n",
              "      <td>0.13000</td>\n",
              "      <td>0.00950</td>\n",
              "      <td>0.07400</td>\n",
              "      <td>0.19700</td>\n",
              "      <td>0.04075</td>\n",
              "      <td>0.41175</td>\n",
              "      <td>0.04775</td>\n",
              "      <td>0.03725</td>\n",
              "      <td>0.20300</td>\n",
              "      <td>0.16325</td>\n",
              "      <td>0.81025</td>\n",
              "      <td>0.01900</td>\n",
              "      <td>0.18175</td>\n",
              "      <td>0.03225</td>\n",
              "      <td>0.04800</td>\n",
              "      <td>0.51925</td>\n",
              "      <td>0.06700</td>\n",
              "      <td>0.01725</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3733 rows × 1128 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "tagId     1.0      2.0      3.0      4.0     ...   1125.0   1126.0   1127.0   1128.0\n",
              "movieId                                      ...                                    \n",
              "1        0.02500  0.02500  0.05775  0.09675  ...  0.01925  0.03625  0.07775  0.02300\n",
              "2        0.03975  0.04375  0.03775  0.04800  ...  0.01550  0.01475  0.09025  0.01875\n",
              "3        0.04350  0.05475  0.02800  0.07700  ...  0.01700  0.01950  0.09700  0.01850\n",
              "5        0.04200  0.05275  0.05925  0.03675  ...  0.01650  0.01675  0.10750  0.01825\n",
              "6        0.02825  0.02550  0.01850  0.04550  ...  0.03525  0.01950  0.06650  0.01900\n",
              "...          ...      ...      ...      ...  ...      ...      ...      ...      ...\n",
              "130496   0.03275  0.03000  0.02400  0.02375  ...  0.05100  0.00825  0.09050  0.01675\n",
              "130520   0.05875  0.02325  0.02150  0.04425  ...  0.01775  0.00850  0.06650  0.01575\n",
              "130578   0.15400  0.04025  0.01975  0.01850  ...  0.04225  0.00525  0.07575  0.01325\n",
              "131013   0.04200  0.03175  0.01700  0.05600  ...  0.02500  0.00950  0.07550  0.01625\n",
              "131168   0.05975  0.10375  0.17850  0.14875  ...  0.04800  0.51925  0.06700  0.01725\n",
              "\n",
              "[3733 rows x 1128 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZgeZPxFYZoPn"
      },
      "source": [
        "credit_list = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LatHkcInElqO"
      },
      "source": [
        "credit_list.append(np.asarray(pivot.values.tolist(), dtype=np.float32))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qFIG_qxnZsYO",
        "outputId": "764261ba-be41-4645-ee06-0e748a38fbba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "credit_list"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([[0.025  , 0.025  , 0.05775, ..., 0.03625, 0.07775, 0.023  ],\n",
              "        [0.03975, 0.04375, 0.03775, ..., 0.01475, 0.09025, 0.01875],\n",
              "        [0.0435 , 0.05475, 0.028  , ..., 0.0195 , 0.097  , 0.0185 ],\n",
              "        ...,\n",
              "        [0.154  , 0.04025, 0.01975, ..., 0.00525, 0.07575, 0.01325],\n",
              "        [0.042  , 0.03175, 0.017  , ..., 0.0095 , 0.0755 , 0.01625],\n",
              "        [0.05975, 0.10375, 0.1785 , ..., 0.51925, 0.067  , 0.01725]],\n",
              "       dtype=float32)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pHLfpw-PZvl7"
      },
      "source": [
        "final = np.array(credit_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iYn1CpV0aIb_",
        "outputId": "0324c0f7-13b6-40f0-e743-6607654697c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "final.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 3733, 1128)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xXRZmGb5j6JH"
      },
      "source": [
        "df1 = df.drop_duplicates(subset=['movieId'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YF24er6Zj9Cw"
      },
      "source": [
        "df1 = df1.reset_index()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ytc7wc-ysc-4",
        "outputId": "5fb9187b-003b-4633-b7b7-2193bec46ca9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 504
        }
      },
      "source": [
        "df1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>level_0</th>\n",
              "      <th>index</th>\n",
              "      <th>movieId</th>\n",
              "      <th>title</th>\n",
              "      <th>Plot</th>\n",
              "      <th>text</th>\n",
              "      <th>tagId</th>\n",
              "      <th>relevance</th>\n",
              "      <th>tag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>Toy Story</td>\n",
              "      <td>In a world where toys are living things who pr...</td>\n",
              "      <td>With \"instant classic\" written all over it, To...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.02500</td>\n",
              "      <td>007</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1128</td>\n",
              "      <td>1128</td>\n",
              "      <td>2</td>\n",
              "      <td>Jumanji</td>\n",
              "      <td>In 1869, near Brantford, New Hampshire, two br...</td>\n",
              "      <td>The result is a thrill ride with enough plunge...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.03975</td>\n",
              "      <td>007</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2256</td>\n",
              "      <td>2256</td>\n",
              "      <td>3</td>\n",
              "      <td>Grumpier Old Men</td>\n",
              "      <td>The feud between Max (Walter Matthau) and John...</td>\n",
              "      <td>Grumpier is a welcome continuation that leaves...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.04350</td>\n",
              "      <td>007</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3384</td>\n",
              "      <td>3384</td>\n",
              "      <td>5</td>\n",
              "      <td>Father of the Bride Part II</td>\n",
              "      <td>The film begins five years after the events of...</td>\n",
              "      <td>nan What Meyers and Shyer have accomplished is...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.04200</td>\n",
              "      <td>007</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4512</td>\n",
              "      <td>4512</td>\n",
              "      <td>6</td>\n",
              "      <td>Heat</td>\n",
              "      <td>Joey Davis is an unemployed former child star ...</td>\n",
              "      <td>Stunningly made and incisively acted by a larg...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.02825</td>\n",
              "      <td>007</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3728</th>\n",
              "      <td>5136912</td>\n",
              "      <td>5138310</td>\n",
              "      <td>130496</td>\n",
              "      <td>Big Game</td>\n",
              "      <td>When Air Force One is shot down by terrorists ...</td>\n",
              "      <td>Onni Tommila, Mr. Helander’s nephew, has an ex...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.03275</td>\n",
              "      <td>007</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3729</th>\n",
              "      <td>5138040</td>\n",
              "      <td>5139438</td>\n",
              "      <td>130520</td>\n",
              "      <td>Home</td>\n",
              "      <td>On the run from their enemy, the so-called pla...</td>\n",
              "      <td>The combination of Home’s layered message, fun...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.05875</td>\n",
              "      <td>007</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3730</th>\n",
              "      <td>5140296</td>\n",
              "      <td>5141694</td>\n",
              "      <td>130578</td>\n",
              "      <td>The Gunman</td>\n",
              "      <td>Jim Terrier (Sean Penn) is a former special fo...</td>\n",
              "      <td>Basically, The Gunman is a movie that asks aud...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.15400</td>\n",
              "      <td>007</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3731</th>\n",
              "      <td>5142552</td>\n",
              "      <td>5143952</td>\n",
              "      <td>131013</td>\n",
              "      <td>Get Hard</td>\n",
              "      <td>James King is an extremely wealthy hedge fund ...</td>\n",
              "      <td>It matches up two comic actors and instead of ...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.04200</td>\n",
              "      <td>007</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3732</th>\n",
              "      <td>5143680</td>\n",
              "      <td>5145081</td>\n",
              "      <td>131168</td>\n",
              "      <td>Phoenix</td>\n",
              "      <td>In Phoenix, Arizona, Harry Collins is a cop wh...</td>\n",
              "      <td>There is intrigue. There is suspense. Guilt - ...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.05975</td>\n",
              "      <td>007</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3733 rows × 9 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      level_0    index  movieId  ... tagId relevance  tag\n",
              "0           0        0        1  ...   1.0   0.02500  007\n",
              "1        1128     1128        2  ...   1.0   0.03975  007\n",
              "2        2256     2256        3  ...   1.0   0.04350  007\n",
              "3        3384     3384        5  ...   1.0   0.04200  007\n",
              "4        4512     4512        6  ...   1.0   0.02825  007\n",
              "...       ...      ...      ...  ...   ...       ...  ...\n",
              "3728  5136912  5138310   130496  ...   1.0   0.03275  007\n",
              "3729  5138040  5139438   130520  ...   1.0   0.05875  007\n",
              "3730  5140296  5141694   130578  ...   1.0   0.15400  007\n",
              "3731  5142552  5143952   131013  ...   1.0   0.04200  007\n",
              "3732  5143680  5145081   131168  ...   1.0   0.05975  007\n",
              "\n",
              "[3733 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TMHAFx3iSynj",
        "outputId": "ebf12398-0cf1-4bb9-db52-350e9485e9e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.python.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.python.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.python.keras.layers import TimeDistributed, Dense, LSTM, Embedding, Dropout, Bidirectional, GlobalMaxPool1D\n",
        "from tensorflow.python.keras.models import Model, Sequential\n",
        "from keras.utils.np_utils import to_categorical# -------- other packages ------------------ #\n",
        "import sys\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from nltk.corpus import stopwords\n",
        "stop_words = set(stopwords.words('english'))\n",
        "import pickle\n",
        "\n",
        "np.set_printoptions(threshold=sys.maxsize)\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL']='2'\n",
        "\n",
        "pd.set_option('display.max_rows', 500)\n",
        "pd.set_option('display.max_columns', 500)\n",
        "pd.set_option('display.width', 1000)\n",
        "\n",
        "df = pd.read_csv(\"/content/drive/My Drive/wikidata.csv\", delimiter = \"\\t\", names = [\"Sentence\", \"Keyword\"])\n",
        "df['Sentence'] = df['Sentence'].astype(str)\n",
        "df['Keyword'] = df['Keyword'].astype(str)\n",
        "\n",
        "def hasNumbers(inputString):\n",
        "\treturn any(char.isdigit() for char in inputString)\n",
        "\n",
        "def tag_keywords(all_keywords):\n",
        "\ttokenizer = Tokenizer()\n",
        "\ttokenizer.fit_on_texts([all_keywords])\n",
        "\tall_keywords = [i for i in tokenizer.word_index.keys()]\n",
        "\tall_keywords = list(set(all_keywords))\n",
        "\treturn all_keywords\n",
        "\n",
        "# sentence cleaning\n",
        "df['Sentence'] = df['Sentence'].apply(lambda x: x.replace(\" – TechCrunch\",\"\"))\n",
        "df['Keyword'] = df['Keyword'].apply(lambda x: tag_keywords(x))\n",
        "\n",
        "sentence_column = []\n",
        "keyword_column = []\n",
        "for index, row in df.iterrows():\n",
        "\tnew_keywords = []\n",
        "\tsentence = row['Sentence']\n",
        "\tkeywords = row['Keyword']\n",
        "\ttokenizer = Tokenizer()\n",
        "\ttokenizer.fit_on_texts([sentence])\n",
        "\ttokens = [i for i in tokenizer.word_index.keys()]\n",
        "\tfor i in tokens:\n",
        "\t\tif i in keywords:\n",
        "\t\t\tif not hasNumbers(i):\n",
        "\t\t\t\tnew_keywords.append(1)\n",
        "\t\telse:\n",
        "\t\t\tnew_keywords.append(0)\n",
        "\tif sum(new_keywords) != 0:\n",
        "\t\tsentence_column.append(sentence)\n",
        "\t\tkeyword_column.append(new_keywords)\n",
        "\n",
        "\n",
        "tokenizer = Tokenizer(oov_token = \"<UNK>\")\n",
        "tokenizer.fit_on_texts(sentence_column)\n",
        "X = tokenizer.texts_to_sequences(sentence_column)\n",
        "X = pad_sequences(X, padding = \"post\", truncating = \"post\", maxlen = 500, value = 0)\n",
        "y = pad_sequences(keyword_column, padding = \"post\", truncating = \"post\", maxlen = 500, value = 0)\n",
        "y = [to_categorical(i, num_classes = 2) for i in y]\n",
        "embeddings_index = {}\n",
        "# e_dat is an embedding file(glove)\n",
        "f = open('/content/drive/My Drive/glove.6B.200d.txt','r')\n",
        "for line in f:\n",
        "\tvalues = line.split()\n",
        "\tword = values[0]\n",
        "\tcoefs = np.asarray(values[1:], dtype = \"float32\")\n",
        "\tembeddings_index[word] = coefs\n",
        "f.close()\n",
        "\n",
        "print('Found %s word vectors.' % len(embeddings_index))\n",
        "\n",
        "EMBEDDING_DIM = 200\n",
        "word_index = tokenizer.word_index\n",
        "embedding_matrix = np.zeros((len(word_index) + 1, EMBEDDING_DIM))\n",
        "for word, i in word_index.items():\n",
        "\tembedding_vector = embeddings_index.get(word)\n",
        "\tif embedding_vector is not None:\n",
        "\t\tembedding_matrix[i] = embedding_vector\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 42)\n",
        "# Model creation\n",
        "model = Sequential()\n",
        "model.add(Embedding(len(word_index) + 1, 200, weights = [embedding_matrix]))\n",
        "model.add(Bidirectional(LSTM(128, return_sequences = True, recurrent_dropout = 0.3)))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Bidirectional(LSTM(128, return_sequences = True, recurrent_dropout = 0.1)))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(TimeDistributed(Dense(2, activation = \"softmax\")))\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer = \"adam\", metrics = [\"accuracy\"])\n",
        "model.fit(X_train, np.array(y_train), batch_size = 32, epochs = 5, validation_split = 0.1)\n",
        "\n",
        "# model save\n",
        "model_json = model.to_json()\n",
        "with open(\"/content/drive/My Drive/model.json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)\n",
        "model.save_weights(\"/content/drive/My Drive/model.h5\")\n",
        "pickle.dump(tokenizer, open(\"tokenizer.pickle\",\"wb\"))\n",
        "print(\"Saved model to disk\")\n",
        "\n",
        "json_file = open('/content/drive/My Drive/model.json', 'r')\n",
        "loaded_model_json = json_file.read()\n",
        "json_file.close()\n",
        "loaded_model = tf.keras.models.model_from_json(loaded_model_json)\n",
        "# load weights into new model\n",
        "loaded_model.load_weights(\"/content/drive/My Drive/model.h5\")\n",
        "print(\"Loaded model from disk\")\n",
        "\n",
        "test_output = loaded_model.predict(X_test)\n",
        "test_output = np.argmax(test_output, axis = -1)\n",
        "\n",
        "\n",
        "flattened_actual = (np.argmax(np.array(y_test), axis = -1)).flatten()\n",
        "flattened_output = test_output.flatten()\n",
        "\n",
        "print(classification_report(flattened_actual, flattened_output))\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "Loaded model from disk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iNw6lh95kEmG",
        "outputId": "cb498a74-c973-4728-f8e2-722eaeac0661",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "from nltk.stem import WordNetLemmatizer \n",
        "try:\n",
        "  while True:\n",
        "    input_ = input(\"Type in a headline:\")\n",
        "    new_t = Tokenizer()\n",
        "    new_t.fit_on_texts([input_])\n",
        "    tokens = [i for i in new_t.word_index.keys()]\n",
        "#\t\tprint(tokens)\n",
        "    actual_tokens = new_t.texts_to_sequences([input_])\n",
        "    inv_map_tokens = {v: k for k, v in new_t.word_index.items()}\n",
        "    actual_tokens = [inv_map_tokens[i] for i in actual_tokens[0]]\n",
        "    tokens = actual_tokens\n",
        "    input_ = tokenizer.texts_to_sequences([input_])\n",
        "    input_ = pad_sequences(input_, padding = \"post\", truncating = \"post\", maxlen = 500, value = 0)\n",
        "    output = loaded_model.predict([input_])\n",
        "    output = np.argmax(output, axis = -1)\n",
        "    where_ = np.where(output[0] == 1)[0]\n",
        "    output_keywords = np.take(tokens, where_)\n",
        "    lem= WordNetLemmatizer()\n",
        "    output_keywords = [lem.lemmatize(word) for word in output_keywords if not word in set(stopwords.words('english'))]\n",
        "    output_keywords = list(set(output_keywords))\n",
        "#\t\tprint(tokens)\n",
        "#\t\tprint(output)\n",
        "    print(output_keywords)\n",
        "    print(len(output_keywords))\n",
        "except KeyboardInterrupt:\n",
        "\tpass"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "['16', 'famous', 'masterwork', 'trouble', 'entire', 'many', 'connected', 'call', 'majid', 'epic', 'anjali', 'save', 'perceives', 'begin', 'renaissance', 'track', 'helped', 'delf', 'law', 'day', \"sartaj's\", 'enforcement', 'ruthless', 'gaitonde', 'find', 'corrupt', \"'nobody'\", 'always', 'richness', 'troubled', 'corruption', 'power', 'sacred', 'caller', '25', 'upon', 'god', 'lie', 'police', 'privileged', 'biggie', 'appreciation', 'sometimes', \"city's\", 'bloodthirsty', 'indian', 'could', 'receives', 'politics', 'senior', 'wretched', 'manages', 'rather', 'busy', 'amid', 'standard', 'keep', 'game', 'blow', 'get', 'beneath', 'year', 'inspector', 'past', 'espionage', 'incident', 'mathur', 'set', 'threatens', 'criminal', 'interweaves', 'location', 'secretly', 'missing', 'ganesh', \"india's\", 'mumbai', 'shoot', 'city', 'life', 'demotivated', 'detail', 'powerful', 'web', 'tell', 'dig', 'searching', 'intricate', 'singh', 'exceptional', 'given', 'since', 'made', 'economic', 'anonymous', 'sartaj', 'arrest', 'sin', 'crime', 'battle', 'lead', 'phone', 'rna', 'cop', 'revel', 'operated', 'parulkar', 'father', 'officer', 'gangster', 'organized']\n",
            "111\n",
            "['western', 'map', 'india', 'hate', 'sadly', 'necessary', 'feeling', 'follow', 'tone', 'issue', 'netflix', 'please', 'language', 'replay', 'likely', 'scene', 'trouble', 'love', 'touching', 'indian', 'game', 'compared', \"i've\", 'violence', 'episode', \"they're\", 'cared', 'take', 'people', 'show', 'truly', 'unable', 'must', 'narcos', 'sacred', 'say', 'world', 'add', 'anymore', 'right', 'political', 'character', 'place', 'twist', 'bad', 'whether', 'turn', 'spoken', 'good', 'hope', 'reviewer', 'harder', 'think', \"can't\", 'worth', 'used', 'face', 'try', 'watch', 'amazing', 'understand', 'enough', 'dubbed', 'fine', 'remember', 'following', 'create', 'little', 'effort', 'engaging', 'amount', 'subtitle', 'sure', 'version', 'unfamiliar', 'heard', 'confusing', 'name', 'plot', 'storyline']\n",
            "80\n",
            "['justice', 'house', 'every', 'muscular', 'binge', 'secondary', 'production', 'notch', 'layer', 'director', 'gripping', 'depth', 'sceptic', 'truly', 'among', \"brother'\", 'vikram', 'bollywood', 'top', 'finesse', 'tense', 'much', 'owns', 'enter', 'action', 'anurag', 'romantic', 'playing', 'task', 'however', 'daring', 'india', 'different', 'fascinating', 'duo', 'saif', 'kashyap', 'show', 'make', 'also', 'head', 'world', 'character', 'cbfc', 'motwane', 'wanted', 'best', 'without', 'changed', 'effort', 'put', 'thought', \"'bunty\", 'social', 'chilling', \"today's\", 'prove', \"'langda\", 'flick', 'would', 'khan', 'book', 'nawazuddin', 'scene', '10', 'explored', 'achieved', 'reservation', 'take', 'injustice', 'direct', 'series', 'bread', 'style', 'badly', 'dark', 'daunting', \"'big\", 'majority', 'current', 'role', 'quite', 'received', 'plot', 'feel', 'relevant', 'tele', 'netflix', 'actor', 'adaptation', 'hour', \"sharma'\", 'religious', 'genre', 'worthy', '3', 'chandra', 'foremost', 'spoiled', 'mushy', 'provoking', 'ali', 'screen', 'amount', 'siddiqui', 'suited']\n",
            "106\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CB7Wic1hU4kK",
        "outputId": "4133b2ec-8981-449f-c67c-e21ca7e5ba84",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qnJAzfXuyKL6"
      },
      "source": [
        "import string\n",
        "def clean_text(text):\n",
        "    '''Make text lowercase, remove text in square brackets,remove links,remove punctuation\n",
        "    and remove words containing numbers.'''\n",
        "    text = text.lower()\n",
        "    text = re.sub('\\[.*?\\]', '', text)\n",
        "    text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n",
        "    text = re.sub('<.*?>+', '', text)\n",
        "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
        "    text = re.sub('\\n', '', text)\n",
        "    text = re.sub('\\w*\\d\\w*', '', text)\n",
        "    lem= WordNetLemmatizer()\n",
        "    text = text.split()\n",
        "    text = [lem.lemmatize(word) for word in text if not word in set(stopwords.words('english'))]\n",
        "    text = ' '.join(text)\n",
        "    return text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "et8wJB4jO3-9"
      },
      "source": [
        "df1['text'] = df1['text'].apply(lambda x: clean_text(x))\n",
        "df1['Plot'] = df1['Plot'].apply(lambda x: clean_text(x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yy4SuzkFmPpr"
      },
      "source": [
        "df1['plot'] = df1['Plot'] + df1['text']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2QBaX-4wgtga",
        "outputId": "5f9d1120-9872-4739-edc0-991f807cf281",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 589
        }
      },
      "source": [
        "df1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>level_0</th>\n",
              "      <th>index</th>\n",
              "      <th>movieId</th>\n",
              "      <th>title</th>\n",
              "      <th>Plot</th>\n",
              "      <th>text</th>\n",
              "      <th>tagId</th>\n",
              "      <th>relevance</th>\n",
              "      <th>tag</th>\n",
              "      <th>plot</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>Toy Story</td>\n",
              "      <td>world toy living thing pretend lifeless human ...</td>\n",
              "      <td>instant classic written toy story first fullle...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.02500</td>\n",
              "      <td>007</td>\n",
              "      <td>world toy living thing pretend lifeless human ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1128</td>\n",
              "      <td>1128</td>\n",
              "      <td>2</td>\n",
              "      <td>Jumanji</td>\n",
              "      <td>near brantford new hampshire two brother bury ...</td>\n",
              "      <td>result thrill ride enough plunge turn loopthel...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.03975</td>\n",
              "      <td>007</td>\n",
              "      <td>near brantford new hampshire two brother bury ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2256</td>\n",
              "      <td>2256</td>\n",
              "      <td>3</td>\n",
              "      <td>Grumpier Old Men</td>\n",
              "      <td>feud max walter matthau john jack lemmon coole...</td>\n",
              "      <td>grumpier welcome continuation leaf wanting ano...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.04350</td>\n",
              "      <td>007</td>\n",
              "      <td>feud max walter matthau john jack lemmon coole...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3384</td>\n",
              "      <td>3384</td>\n",
              "      <td>5</td>\n",
              "      <td>Father of the Bride Part II</td>\n",
              "      <td>film begin five year event first one george ba...</td>\n",
              "      <td>nan meyers shyer accomplished create pleasant ...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.04200</td>\n",
              "      <td>007</td>\n",
              "      <td>film begin five year event first one george ba...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4512</td>\n",
              "      <td>4512</td>\n",
              "      <td>6</td>\n",
              "      <td>Heat</td>\n",
              "      <td>joey davis unemployed former child star suppor...</td>\n",
              "      <td>stunningly made incisively acted large terrifi...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.02825</td>\n",
              "      <td>007</td>\n",
              "      <td>joey davis unemployed former child star suppor...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3728</th>\n",
              "      <td>5136912</td>\n",
              "      <td>5138310</td>\n",
              "      <td>130496</td>\n",
              "      <td>Big Game</td>\n",
              "      <td>air force one shot terrorist leaving president...</td>\n",
              "      <td>onni tommila mr helander’s nephew expressive f...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.03275</td>\n",
              "      <td>007</td>\n",
              "      <td>air force one shot terrorist leaving president...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3729</th>\n",
              "      <td>5138040</td>\n",
              "      <td>5139438</td>\n",
              "      <td>130520</td>\n",
              "      <td>Home</td>\n",
              "      <td>run enemy socalled planetdestroying gorg alien...</td>\n",
              "      <td>combination home’s layered message fun score c...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.05875</td>\n",
              "      <td>007</td>\n",
              "      <td>run enemy socalled planetdestroying gorg alien...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3730</th>\n",
              "      <td>5140296</td>\n",
              "      <td>5141694</td>\n",
              "      <td>130578</td>\n",
              "      <td>The Gunman</td>\n",
              "      <td>jim terrier sean penn former special force sol...</td>\n",
              "      <td>basically gunman movie asks audience sympathiz...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.15400</td>\n",
              "      <td>007</td>\n",
              "      <td>jim terrier sean penn former special force sol...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3731</th>\n",
              "      <td>5142552</td>\n",
              "      <td>5143952</td>\n",
              "      <td>131013</td>\n",
              "      <td>Get Hard</td>\n",
              "      <td>james king extremely wealthy hedge fund manage...</td>\n",
              "      <td>match two comic actor instead clashing canceli...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.04200</td>\n",
              "      <td>007</td>\n",
              "      <td>james king extremely wealthy hedge fund manage...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3732</th>\n",
              "      <td>5143680</td>\n",
              "      <td>5145081</td>\n",
              "      <td>131168</td>\n",
              "      <td>Phoenix</td>\n",
              "      <td>phoenix arizona harry collins cop whose compul...</td>\n",
              "      <td>intrigue suspense guilt man guilt nation hang ...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.05975</td>\n",
              "      <td>007</td>\n",
              "      <td>phoenix arizona harry collins cop whose compul...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3733 rows × 10 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      level_0    index  movieId                        title                                               Plot                                               text  tagId  relevance  tag                                               plot\n",
              "0           0        0        1                    Toy Story  world toy living thing pretend lifeless human ...  instant classic written toy story first fullle...    1.0    0.02500  007  world toy living thing pretend lifeless human ...\n",
              "1        1128     1128        2                      Jumanji  near brantford new hampshire two brother bury ...  result thrill ride enough plunge turn loopthel...    1.0    0.03975  007  near brantford new hampshire two brother bury ...\n",
              "2        2256     2256        3             Grumpier Old Men  feud max walter matthau john jack lemmon coole...  grumpier welcome continuation leaf wanting ano...    1.0    0.04350  007  feud max walter matthau john jack lemmon coole...\n",
              "3        3384     3384        5  Father of the Bride Part II  film begin five year event first one george ba...  nan meyers shyer accomplished create pleasant ...    1.0    0.04200  007  film begin five year event first one george ba...\n",
              "4        4512     4512        6                         Heat  joey davis unemployed former child star suppor...  stunningly made incisively acted large terrifi...    1.0    0.02825  007  joey davis unemployed former child star suppor...\n",
              "...       ...      ...      ...                          ...                                                ...                                                ...    ...        ...  ...                                                ...\n",
              "3728  5136912  5138310   130496                     Big Game  air force one shot terrorist leaving president...  onni tommila mr helander’s nephew expressive f...    1.0    0.03275  007  air force one shot terrorist leaving president...\n",
              "3729  5138040  5139438   130520                         Home  run enemy socalled planetdestroying gorg alien...  combination home’s layered message fun score c...    1.0    0.05875  007  run enemy socalled planetdestroying gorg alien...\n",
              "3730  5140296  5141694   130578                   The Gunman  jim terrier sean penn former special force sol...  basically gunman movie asks audience sympathiz...    1.0    0.15400  007  jim terrier sean penn former special force sol...\n",
              "3731  5142552  5143952   131013                     Get Hard  james king extremely wealthy hedge fund manage...  match two comic actor instead clashing canceli...    1.0    0.04200  007  james king extremely wealthy hedge fund manage...\n",
              "3732  5143680  5145081   131168                      Phoenix  phoenix arizona harry collins cop whose compul...  intrigue suspense guilt man guilt nation hang ...    1.0    0.05975  007  phoenix arizona harry collins cop whose compul...\n",
              "\n",
              "[3733 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d6L9419JNeFO"
      },
      "source": [
        "plot = df1['plot'].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dz30rrlbVi9-"
      },
      "source": [
        "word_tokenizer = Tokenizer()\n",
        "word_tokenizer.fit_on_texts(plot)\n",
        "vocab_length = len(word_tokenizer.word_index) + 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9dVdMAiNbAzW"
      },
      "source": [
        "longest_train = max(plot, key=lambda sentence: len(word_tokenize(sentence)))\n",
        "length_long_sentence = len(word_tokenize(longest_train))\n",
        "padded_sentences = pad_sequences(word_tokenizer.texts_to_sequences(plot), 50, padding='post')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vELqWTIAbA2B",
        "outputId": "be2b017c-6bf1-4035-e55f-5c519abe862b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "embeddings_index = {}\n",
        "# embedding file(glove)\n",
        "f = open('/content/drive/My Drive/glove.6B.100d.txt','r')\n",
        "for line in f:\n",
        "\tvalues = line.split()\n",
        "\tword = values[0]\n",
        "\tcoefs = np.asarray(values[1:], dtype = \"float32\")\n",
        "\tembeddings_index[word] = coefs\n",
        "f.close()\n",
        "\n",
        "print('Found %s word vectors.' % len(embeddings_index))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 400000 word vectors.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hfbMAoXyJwPH"
      },
      "source": [
        "EMBEDDING_DIM = 100\n",
        "word_index = word_tokenizer.word_index\n",
        "embedding_matrix = np.zeros((len(word_index) + 1, EMBEDDING_DIM))\n",
        "for word, i in word_index.items():\n",
        "\tembedding_vector = embeddings_index.get(word)\n",
        "\tif embedding_vector is not None:\n",
        "\t\tembedding_matrix[i] = embedding_vector"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9SFi2yo3vr1Z"
      },
      "source": [
        "result = final[0, :, :]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LuKOqfUwVJ8o"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split( padded_sentences, result, test_size=0.1, random_state=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OXhNQwcCNeR3"
      },
      "source": [
        "def BLSTM():\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(input_dim=len(word_index)+1, \n",
        "                        output_dim=100, \n",
        "                        weights = [embedding_matrix],\n",
        "                        input_length = 50))\n",
        "    model.add(Bidirectional(LSTM(50, return_sequences = True, recurrent_dropout=0.2)))\n",
        "    model.add(Bidirectional(LSTM( 256, return_sequences = True, recurrent_dropout=0.2)))\n",
        "    model.add(GlobalMaxPool1D())\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(2048, activation = \"relu\"))\n",
        "    model.add(Dense(1024, activation = \"relu\"))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(1128, activation = 'sigmoid'))\n",
        "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "    return model\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q_Cw5DJ9BQMR",
        "outputId": "64fbd4e3-3951-4cae-dc61-231546c48f65",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 180
        }
      },
      "source": [
        "from keras.utils.vis_utils import plot_model\n",
        "plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-52-1a9ac285782f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvis_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mplot_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplot_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'model_plot.png'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_layer_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AMoNq_WM6QTf"
      },
      "source": [
        "def build_lrfn(lr_start=0.00001, lr_max=0.000075, \n",
        "               lr_min=0.000001, lr_rampup_epochs=20, \n",
        "               lr_sustain_epochs=0, lr_exp_decay=.8):\n",
        "    \n",
        "    def lrfn(epoch):\n",
        "        if epoch < lr_rampup_epochs:\n",
        "            lr = (lr_max - lr_start) / lr_rampup_epochs * epoch + lr_start\n",
        "        elif epoch < lr_rampup_epochs + lr_sustain_epochs:\n",
        "            lr = lr_max\n",
        "        else:\n",
        "            lr = (lr_max - lr_min) * lr_exp_decay**(epoch - lr_rampup_epochs - lr_sustain_epochs) + lr_min\n",
        "        return lr\n",
        "    \n",
        "    return lrfn\n",
        "\n",
        "lrfn = build_lrfn()\n",
        "lr_schedule = tf.keras.callbacks.LearningRateScheduler(lrfn, verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yeiT43MENegr",
        "outputId": "2bd49e83-ab05-4d87-d2a3-300d70316ad9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model = BLSTM()\n",
        "checkpoint = ModelCheckpoint(\n",
        "    '/content/drive/My Drive/model_tag.h5', \n",
        "    monitor = 'val_loss', \n",
        "    verbose = 1, \n",
        "    save_best_only = True\n",
        ")\n",
        "\n",
        "history = model.fit(\n",
        "    X_train, \n",
        "    y_train,\n",
        "    epochs = 100,\n",
        "    batch_size = 64,\n",
        "    validation_data = [X_test, y_test],\n",
        "    verbose = 1,\n",
        "    callbacks = [checkpoint, lr_schedule],\n",
        "    shuffle=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 00001: LearningRateScheduler reducing learning rate to 1e-05.\n",
            "Epoch 1/100\n",
            "53/53 [==============================] - ETA: 0s - loss: 0.2342\n",
            "Epoch 00001: val_loss improved from inf to 0.00000, saving model to /content/drive/My Drive/model_tag.h5\n",
            "53/53 [==============================] - 47s 886ms/step - loss: 0.2342 - val_loss: 0.0000e+00\n",
            "\n",
            "Epoch 00002: LearningRateScheduler reducing learning rate to 1.325e-05.\n",
            "Epoch 2/100\n",
            "53/53 [==============================] - ETA: 0s - loss: 0.2327\n",
            "Epoch 00002: val_loss did not improve from 0.00000\n",
            "53/53 [==============================] - 45s 848ms/step - loss: 0.2327 - val_loss: 0.0000e+00\n",
            "\n",
            "Epoch 00003: LearningRateScheduler reducing learning rate to 1.65e-05.\n",
            "Epoch 3/100\n",
            "53/53 [==============================] - ETA: 0s - loss: 0.2309\n",
            "Epoch 00003: val_loss did not improve from 0.00000\n",
            "53/53 [==============================] - 45s 845ms/step - loss: 0.2309 - val_loss: 0.0000e+00\n",
            "\n",
            "Epoch 00004: LearningRateScheduler reducing learning rate to 1.975e-05.\n",
            "Epoch 4/100\n",
            "53/53 [==============================] - ETA: 0s - loss: 0.2282\n",
            "Epoch 00004: val_loss did not improve from 0.00000\n",
            "53/53 [==============================] - 44s 840ms/step - loss: 0.2282 - val_loss: 0.0000e+00\n",
            "\n",
            "Epoch 00005: LearningRateScheduler reducing learning rate to 2.3e-05.\n",
            "Epoch 5/100\n",
            "53/53 [==============================] - ETA: 0s - loss: 0.2246\n",
            "Epoch 00005: val_loss did not improve from 0.00000\n",
            "53/53 [==============================] - 44s 832ms/step - loss: 0.2246 - val_loss: 0.0000e+00\n",
            "\n",
            "Epoch 00006: LearningRateScheduler reducing learning rate to 2.625e-05.\n",
            "Epoch 6/100\n",
            "53/53 [==============================] - ETA: 0s - loss: 0.2210\n",
            "Epoch 00006: val_loss did not improve from 0.00000\n",
            "53/53 [==============================] - 44s 839ms/step - loss: 0.2210 - val_loss: 0.0000e+00\n",
            "\n",
            "Epoch 00007: LearningRateScheduler reducing learning rate to 2.95e-05.\n",
            "Epoch 7/100\n",
            "53/53 [==============================] - ETA: 0s - loss: 0.2161\n",
            "Epoch 00007: val_loss did not improve from 0.00000\n",
            "53/53 [==============================] - 44s 827ms/step - loss: 0.2161 - val_loss: 0.0000e+00\n",
            "\n",
            "Epoch 00008: LearningRateScheduler reducing learning rate to 3.2749999999999996e-05.\n",
            "Epoch 8/100\n",
            "53/53 [==============================] - ETA: 0s - loss: 0.2093\n",
            "Epoch 00008: val_loss did not improve from 0.00000\n",
            "53/53 [==============================] - 44s 831ms/step - loss: 0.2093 - val_loss: 0.0000e+00\n",
            "\n",
            "Epoch 00009: LearningRateScheduler reducing learning rate to 3.6e-05.\n",
            "Epoch 9/100\n",
            "53/53 [==============================] - ETA: 0s - loss: 0.1968\n",
            "Epoch 00009: val_loss did not improve from 0.00000\n",
            "53/53 [==============================] - 44s 831ms/step - loss: 0.1968 - val_loss: 0.0000e+00\n",
            "\n",
            "Epoch 00010: LearningRateScheduler reducing learning rate to 3.925e-05.\n",
            "Epoch 10/100\n",
            "53/53 [==============================] - ETA: 0s - loss: 0.1793\n",
            "Epoch 00010: val_loss did not improve from 0.00000\n",
            "53/53 [==============================] - 44s 837ms/step - loss: 0.1793 - val_loss: 0.0000e+00\n",
            "\n",
            "Epoch 00011: LearningRateScheduler reducing learning rate to 4.2499999999999996e-05.\n",
            "Epoch 11/100\n",
            "53/53 [==============================] - ETA: 0s - loss: 0.1613\n",
            "Epoch 00011: val_loss did not improve from 0.00000\n",
            "53/53 [==============================] - 44s 831ms/step - loss: 0.1613 - val_loss: 0.0000e+00\n",
            "\n",
            "Epoch 00012: LearningRateScheduler reducing learning rate to 4.5749999999999994e-05.\n",
            "Epoch 12/100\n",
            "53/53 [==============================] - ETA: 0s - loss: 0.1407\n",
            "Epoch 00012: val_loss did not improve from 0.00000\n",
            "53/53 [==============================] - 44s 837ms/step - loss: 0.1407 - val_loss: 0.0000e+00\n",
            "\n",
            "Epoch 00013: LearningRateScheduler reducing learning rate to 4.9e-05.\n",
            "Epoch 13/100\n",
            "53/53 [==============================] - ETA: 0s - loss: 0.1187\n",
            "Epoch 00013: val_loss did not improve from 0.00000\n",
            "53/53 [==============================] - 45s 841ms/step - loss: 0.1187 - val_loss: 0.0000e+00\n",
            "\n",
            "Epoch 00014: LearningRateScheduler reducing learning rate to 5.2249999999999996e-05.\n",
            "Epoch 14/100\n",
            "53/53 [==============================] - ETA: 0s - loss: 0.1004\n",
            "Epoch 00014: val_loss did not improve from 0.00000\n",
            "53/53 [==============================] - 44s 833ms/step - loss: 0.1004 - val_loss: 0.0000e+00\n",
            "\n",
            "Epoch 00015: LearningRateScheduler reducing learning rate to 5.5499999999999994e-05.\n",
            "Epoch 15/100\n",
            "53/53 [==============================] - ETA: 0s - loss: 0.0814\n",
            "Epoch 00015: val_loss did not improve from 0.00000\n",
            "53/53 [==============================] - 44s 830ms/step - loss: 0.0814 - val_loss: 0.0000e+00\n",
            "\n",
            "Epoch 00016: LearningRateScheduler reducing learning rate to 5.875e-05.\n",
            "Epoch 16/100\n",
            "53/53 [==============================] - ETA: 0s - loss: 0.0740\n",
            "Epoch 00016: val_loss did not improve from 0.00000\n",
            "53/53 [==============================] - 45s 842ms/step - loss: 0.0740 - val_loss: 0.0000e+00\n",
            "\n",
            "Epoch 00017: LearningRateScheduler reducing learning rate to 6.2e-05.\n",
            "Epoch 17/100\n",
            "53/53 [==============================] - ETA: 0s - loss: 0.0684\n",
            "Epoch 00017: val_loss did not improve from 0.00000\n",
            "53/53 [==============================] - 45s 856ms/step - loss: 0.0684 - val_loss: 0.0000e+00\n",
            "\n",
            "Epoch 00018: LearningRateScheduler reducing learning rate to 6.525e-05.\n",
            "Epoch 18/100\n",
            "53/53 [==============================] - ETA: 0s - loss: 0.0576\n",
            "Epoch 00018: val_loss did not improve from 0.00000\n",
            "53/53 [==============================] - 44s 839ms/step - loss: 0.0576 - val_loss: 0.0000e+00\n",
            "\n",
            "Epoch 00019: LearningRateScheduler reducing learning rate to 6.85e-05.\n",
            "Epoch 19/100\n",
            "53/53 [==============================] - ETA: 0s - loss: 0.0583\n",
            "Epoch 00019: val_loss did not improve from 0.00000\n",
            "53/53 [==============================] - 45s 851ms/step - loss: 0.0583 - val_loss: 0.0000e+00\n",
            "\n",
            "Epoch 00020: LearningRateScheduler reducing learning rate to 7.175e-05.\n",
            "Epoch 20/100\n",
            "53/53 [==============================] - ETA: 0s - loss: 0.0516\n",
            "Epoch 00020: val_loss did not improve from 0.00000\n",
            "53/53 [==============================] - 45s 849ms/step - loss: 0.0516 - val_loss: 0.0000e+00\n",
            "\n",
            "Epoch 00021: LearningRateScheduler reducing learning rate to 7.5e-05.\n",
            "Epoch 21/100\n",
            "53/53 [==============================] - ETA: 0s - loss: 0.0498\n",
            "Epoch 00021: val_loss did not improve from 0.00000\n",
            "53/53 [==============================] - 45s 852ms/step - loss: 0.0498 - val_loss: 0.0000e+00\n",
            "\n",
            "Epoch 00022: LearningRateScheduler reducing learning rate to 6.02e-05.\n",
            "Epoch 22/100\n",
            "53/53 [==============================] - ETA: 0s - loss: 0.0460\n",
            "Epoch 00022: val_loss did not improve from 0.00000\n",
            "53/53 [==============================] - 45s 845ms/step - loss: 0.0460 - val_loss: 0.0000e+00\n",
            "\n",
            "Epoch 00023: LearningRateScheduler reducing learning rate to 4.8360000000000005e-05.\n",
            "Epoch 23/100\n",
            "53/53 [==============================] - ETA: 0s - loss: 0.0443\n",
            "Epoch 00023: val_loss did not improve from 0.00000\n",
            "53/53 [==============================] - 45s 847ms/step - loss: 0.0443 - val_loss: 0.0000e+00\n",
            "\n",
            "Epoch 00024: LearningRateScheduler reducing learning rate to 3.8888000000000004e-05.\n",
            "Epoch 24/100\n",
            "53/53 [==============================] - ETA: 0s - loss: 0.0436\n",
            "Epoch 00024: val_loss did not improve from 0.00000\n",
            "53/53 [==============================] - 45s 843ms/step - loss: 0.0436 - val_loss: 0.0000e+00\n",
            "\n",
            "Epoch 00025: LearningRateScheduler reducing learning rate to 3.1310400000000004e-05.\n",
            "Epoch 25/100\n",
            "53/53 [==============================] - ETA: 0s - loss: 0.0459\n",
            "Epoch 00025: val_loss did not improve from 0.00000\n",
            "53/53 [==============================] - 45s 846ms/step - loss: 0.0459 - val_loss: 0.0000e+00\n",
            "\n",
            "Epoch 00026: LearningRateScheduler reducing learning rate to 2.5248320000000005e-05.\n",
            "Epoch 26/100\n",
            "53/53 [==============================] - ETA: 0s - loss: 0.0414\n",
            "Epoch 00026: val_loss did not improve from 0.00000\n",
            "53/53 [==============================] - 45s 848ms/step - loss: 0.0414 - val_loss: 0.0000e+00\n",
            "\n",
            "Epoch 00027: LearningRateScheduler reducing learning rate to 2.0398656000000008e-05.\n",
            "Epoch 27/100\n",
            "53/53 [==============================] - ETA: 0s - loss: 0.0410\n",
            "Epoch 00027: val_loss did not improve from 0.00000\n",
            "53/53 [==============================] - 45s 848ms/step - loss: 0.0410 - val_loss: 0.0000e+00\n",
            "\n",
            "Epoch 00028: LearningRateScheduler reducing learning rate to 1.6518924800000004e-05.\n",
            "Epoch 28/100\n",
            "53/53 [==============================] - ETA: 0s - loss: 0.0403\n",
            "Epoch 00028: val_loss did not improve from 0.00000\n",
            "53/53 [==============================] - 45s 847ms/step - loss: 0.0403 - val_loss: 0.0000e+00\n",
            "\n",
            "Epoch 00029: LearningRateScheduler reducing learning rate to 1.3415139840000007e-05.\n",
            "Epoch 29/100\n",
            "53/53 [==============================] - ETA: 0s - loss: 0.0420\n",
            "Epoch 00029: val_loss did not improve from 0.00000\n",
            "53/53 [==============================] - 45s 844ms/step - loss: 0.0420 - val_loss: 0.0000e+00\n",
            "\n",
            "Epoch 00030: LearningRateScheduler reducing learning rate to 1.0932111872000004e-05.\n",
            "Epoch 30/100\n",
            "53/53 [==============================] - ETA: 0s - loss: 0.0421\n",
            "Epoch 00030: val_loss did not improve from 0.00000\n",
            "53/53 [==============================] - 45s 849ms/step - loss: 0.0421 - val_loss: 0.0000e+00\n",
            "\n",
            "Epoch 00031: LearningRateScheduler reducing learning rate to 8.945689497600004e-06.\n",
            "Epoch 31/100\n",
            "53/53 [==============================] - ETA: 0s - loss: 0.0438\n",
            "Epoch 00031: val_loss did not improve from 0.00000\n",
            "53/53 [==============================] - 45s 854ms/step - loss: 0.0438 - val_loss: 0.0000e+00\n",
            "\n",
            "Epoch 00032: LearningRateScheduler reducing learning rate to 7.356551598080003e-06.\n",
            "Epoch 32/100\n",
            "53/53 [==============================] - ETA: 0s - loss: 0.0408\n",
            "Epoch 00032: val_loss did not improve from 0.00000\n",
            "53/53 [==============================] - 45s 841ms/step - loss: 0.0408 - val_loss: 0.0000e+00\n",
            "\n",
            "Epoch 00033: LearningRateScheduler reducing learning rate to 6.085241278464003e-06.\n",
            "Epoch 33/100\n",
            "53/53 [==============================] - ETA: 0s - loss: 0.0392\n",
            "Epoch 00033: val_loss did not improve from 0.00000\n",
            "53/53 [==============================] - 45s 846ms/step - loss: 0.0392 - val_loss: 0.0000e+00\n",
            "\n",
            "Epoch 00034: LearningRateScheduler reducing learning rate to 5.068193022771202e-06.\n",
            "Epoch 34/100\n",
            "53/53 [==============================] - ETA: 0s - loss: 0.0443\n",
            "Epoch 00034: val_loss did not improve from 0.00000\n",
            "53/53 [==============================] - 45s 846ms/step - loss: 0.0443 - val_loss: 0.0000e+00\n",
            "\n",
            "Epoch 00035: LearningRateScheduler reducing learning rate to 4.254554418216963e-06.\n",
            "Epoch 35/100\n",
            "24/53 [============>.................] - ETA: 24s - loss: 0.0430"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-78-0bd6e859e7ff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr_schedule\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     shuffle=True)\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    805\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[1;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1924\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TD3glaJd4rjx"
      },
      "source": [
        "model_json = model.to_json()\n",
        "with open(\"/content/drive/My Drive/model_sys.json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EvTWQzReG2M4",
        "outputId": "dd320c1d-45d4-468d-f610-7d3eecf84d97",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "source": [
        "json_file = open('/content/drive/My Drive/model_sys.json', 'r')\n",
        "loaded_model_json = json_file.read()\n",
        "json_file.close()\n",
        "loaded_model = tf.keras.models.model_from_json(loaded_model_json)\n",
        "# load weights into new model\n",
        "loaded_model.load_weights(\"/content/drive/My Drive/model_tag.h5\")\n",
        "print(\"Loaded model from disk\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "Loaded model from disk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rFwTIWWEa4IQ",
        "outputId": "8c33e243-6e93-4f76-da19-6247372e1455",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "print(model.history.history.keys())\n",
        "\n",
        "plt.plot(model.history.history['loss'])\n",
        "plt.plot(model.history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dict_keys(['loss', 'val_loss', 'lr'])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NKW0Lp4RNeNW",
        "outputId": "f1691434-a33e-4f5c-847c-7d69d8fad2ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 507
        }
      },
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "output_pred = []\n",
        "def reemovNestings(l): \n",
        "    for i in l: \n",
        "        if type(i) == list: \n",
        "            reemovNestings(i) \n",
        "        else: \n",
        "            output_pred.append(i)\n",
        "input_ = input(\"Type in a headline:\")\n",
        "new_t = Tokenizer()\n",
        "new_t.fit_on_texts([input_])\n",
        "tokens = [i for i in new_t.word_index.keys()]\n",
        "#\t\tprint(tokens)\n",
        "actual_tokens = new_t.texts_to_sequences([input_])\n",
        "inv_map_tokens = {v: k for k, v in new_t.word_index.items()}\n",
        "actual_tokens = [inv_map_tokens[i] for i in actual_tokens[0]]\n",
        "tokens = actual_tokens\n",
        "input_ = tokenizer.texts_to_sequences([input_])\n",
        "input_ = pad_sequences(input_, padding = \"post\", truncating = \"post\", maxlen = 500, value = 0)\n",
        "output = loaded_model.predict([input_])\n",
        "output = output.tolist()\n",
        "reemovNestings(output)\n",
        "print(output_pred)\n",
        "genome_tags['score'] = output_pred\n",
        "genome_tags"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "Type in a headline:Sartaj Singh, a Mumbai police officer, receives an anonymous phone call from a gangster who threatens to blow up the entire city. Amid the corrupt standards of Indian law enforcement begins a battle between a 'nobody' cop and ruthless gangster who perceives (sometimes) himself to be a God.\n",
            "[0.5291510224342346, 0.4556431472301483, 0.5153481364250183, 0.4766722619533539, 0.4980277419090271, 0.5067722201347351, 0.49445995688438416, 0.46300914883613586, 0.49219924211502075, 0.48933905363082886, 0.4822453558444977, 0.4982876479625702, 0.48964163661003113, 0.49094468355178833, 0.48928239941596985, 0.4815347492694855, 0.4596268832683563, 0.46054935455322266, 0.5207793712615967, 0.5364999175071716, 0.5119513869285583, 0.5097345113754272, 0.48547545075416565, 0.49479010701179504, 0.5465853214263916, 0.5254980325698853, 0.4534824788570404, 0.5333465337753296, 0.4776037931442261, 0.5191141366958618, 0.5069217681884766, 0.4796939194202423, 0.5121201276779175, 0.49985232949256897, 0.48280346393585205, 0.49138128757476807, 0.5170586109161377, 0.5025298595428467, 0.5386703014373779, 0.5262848138809204, 0.5458847880363464, 0.49720239639282227, 0.47518089413642883, 0.48368415236473083, 0.5067190527915955, 0.5029564499855042, 0.4831249713897705, 0.5066710710525513, 0.4702202081680298, 0.48595258593559265, 0.5376931428909302, 0.5383328795433044, 0.5061559081077576, 0.4921140670776367, 0.4967992305755615, 0.4910043478012085, 0.4704664647579193, 0.49041521549224854, 0.4865017831325531, 0.5320297479629517, 0.5166702270507812, 0.5147991180419922, 0.5359826683998108, 0.4951886236667633, 0.4943912923336029, 0.5349547266960144, 0.5036747455596924, 0.5100911855697632, 0.478007972240448, 0.5124879479408264, 0.5153120160102844, 0.5489078760147095, 0.5204724073410034, 0.48341959714889526, 0.5103630423545837, 0.4924420714378357, 0.522610604763031, 0.5138335227966309, 0.49397051334381104, 0.4915156960487366, 0.5040934681892395, 0.5078523755073547, 0.48971858620643616, 0.4896836578845978, 0.4972706139087677, 0.5011005997657776, 0.46515122056007385, 0.49062395095825195, 0.5238457322120667, 0.5218286514282227, 0.46554964780807495, 0.49934831261634827, 0.47988319396972656, 0.5338950753211975, 0.49409961700439453, 0.472835510969162, 0.47217854857444763, 0.5412247776985168, 0.529601514339447, 0.4895935654640198, 0.4779624342918396, 0.49254292249679565, 0.46683788299560547, 0.47938814759254456, 0.5395830273628235, 0.5266793370246887, 0.45061978697776794, 0.4837418496608734, 0.5150715112686157, 0.5267345309257507, 0.504041314125061, 0.4663819968700409, 0.523991584777832, 0.5065509080886841, 0.4908336400985718, 0.48369404673576355, 0.5262191295623779, 0.4858599901199341, 0.5213902592658997, 0.5212174654006958, 0.5025233626365662, 0.5108609199523926, 0.527287483215332, 0.5155614018440247, 0.5278838872909546, 0.47896793484687805, 0.5149001479148865, 0.4845375120639801, 0.4861748218536377, 0.47572827339172363, 0.5219928026199341, 0.484149694442749, 0.48936113715171814, 0.48481452465057373, 0.5050123929977417, 0.5016140937805176, 0.5150386095046997, 0.5110599994659424, 0.5179330110549927, 0.5131657719612122, 0.4962962567806244, 0.5479258894920349, 0.4926432967185974, 0.45938560366630554, 0.45534417033195496, 0.5375432968139648, 0.48219114542007446, 0.5066347718238831, 0.47555097937583923, 0.5008291602134705, 0.4971654415130615, 0.5308610796928406, 0.49347755312919617, 0.49988463521003723, 0.49351173639297485, 0.49397438764572144, 0.4862213134765625, 0.4776243269443512, 0.46531450748443604, 0.5029217004776001, 0.4886603355407715, 0.5009616613388062, 0.5208787322044373, 0.503634512424469, 0.48329001665115356, 0.5052642822265625, 0.4841894805431366, 0.5247664451599121, 0.5143083333969116, 0.5124988555908203, 0.4979695677757263, 0.5081499218940735, 0.4746682047843933, 0.5002830028533936, 0.48511362075805664, 0.48301753401756287, 0.5044289231300354, 0.49022701382637024, 0.5245079398155212, 0.5149269700050354, 0.48281657695770264, 0.5339062809944153, 0.4928888976573944, 0.49723517894744873, 0.4920334815979004, 0.4877619445323944, 0.523709774017334, 0.482189804315567, 0.46149781346321106, 0.49324581027030945, 0.5218984484672546, 0.4849008321762085, 0.5079771876335144, 0.5124797821044922, 0.5099406838417053, 0.5171681046485901, 0.4997314512729645, 0.4809122383594513, 0.5016506910324097, 0.4845697581768036, 0.4631611406803131, 0.49454647302627563, 0.5233851075172424, 0.503594160079956, 0.5366153120994568, 0.5037399530410767, 0.5355349779129028, 0.5004500150680542, 0.4642294645309448, 0.5226985216140747, 0.5294428467750549, 0.48806264996528625, 0.5192484855651855, 0.49445971846580505, 0.5121637582778931, 0.5061476230621338, 0.49789637327194214, 0.46110448241233826, 0.5436418056488037, 0.5016118288040161, 0.5214849710464478, 0.4636465013027191, 0.4993348717689514, 0.48731446266174316, 0.5042626857757568, 0.49970585107803345, 0.4892785847187042, 0.5045811533927917, 0.46737873554229736, 0.5298850536346436, 0.48768991231918335, 0.47865670919418335, 0.5037463307380676, 0.48498186469078064, 0.4909341335296631, 0.5158565640449524, 0.5320524573326111, 0.5074369311332703, 0.48217707872390747, 0.5010033845901489, 0.4964991807937622, 0.4843780994415283, 0.48513880372047424, 0.5030311346054077, 0.5137929916381836, 0.5172819495201111, 0.4995114803314209, 0.49311012029647827, 0.5346264243125916, 0.5154342651367188, 0.5052618980407715, 0.5010771155357361, 0.5060669779777527, 0.5012662410736084, 0.5005701780319214, 0.5053836107254028, 0.5182956457138062, 0.5040113925933838, 0.4781029522418976, 0.4984743893146515, 0.5242786407470703, 0.5116366147994995, 0.4539046287536621, 0.5149703621864319, 0.5416592359542847, 0.488467812538147, 0.5067622065544128, 0.47290509939193726, 0.5207428932189941, 0.4770280122756958, 0.5061333775520325, 0.49271610379219055, 0.49515500664711, 0.4797171354293823, 0.5116453766822815, 0.5174353122711182, 0.5170483589172363, 0.49172890186309814, 0.5222413539886475, 0.48271480202674866, 0.5186080932617188, 0.49897992610931396, 0.5217189788818359, 0.5314808487892151, 0.4907349646091461, 0.49771687388420105, 0.48154863715171814, 0.47756972908973694, 0.5028741955757141, 0.528562068939209, 0.49111467599868774, 0.4637785851955414, 0.4965830147266388, 0.5006535649299622, 0.4769742488861084, 0.4879644215106964, 0.5011631846427917, 0.4727373421192169, 0.4969898462295532, 0.48360368609428406, 0.4967612326145172, 0.49859657883644104, 0.48428934812545776, 0.5127885341644287, 0.45990610122680664, 0.539882481098175, 0.519567608833313, 0.47924989461898804, 0.5136115550994873, 0.5062563419342041, 0.5011922121047974, 0.5331568717956543, 0.5035886764526367, 0.4714757204055786, 0.4897575378417969, 0.489643394947052, 0.5034266114234924, 0.49277931451797485, 0.4964722692966461, 0.4909626841545105, 0.5292321443557739, 0.4729529619216919, 0.5107682347297668, 0.46416690945625305, 0.5107051134109497, 0.5191609263420105, 0.4827018976211548, 0.5595609545707703, 0.5036290287971497, 0.5040869116783142, 0.5301623940467834, 0.5357286930084229, 0.5002531409263611, 0.5084804892539978, 0.4753466248512268, 0.4662523567676544, 0.4981708824634552, 0.5086463093757629, 0.5146450996398926, 0.4869101047515869, 0.47156333923339844, 0.4834311306476593, 0.5094513297080994, 0.5132576823234558, 0.511979877948761, 0.4905546307563782, 0.4785865843296051, 0.4816732704639435, 0.4888722598552704, 0.5161210298538208, 0.49319419264793396, 0.4993721842765808, 0.48479950428009033, 0.5073568224906921, 0.4906890392303467, 0.5011994242668152, 0.505957305431366, 0.4958580434322357, 0.4892091453075409, 0.5038261413574219, 0.520445704460144, 0.49485841393470764, 0.4861871004104614, 0.4676690101623535, 0.4890580177307129, 0.49548354744911194, 0.5020197629928589, 0.4848747253417969, 0.5064797401428223, 0.5369129180908203, 0.4983031153678894, 0.4915275573730469, 0.48350808024406433, 0.5060356259346008, 0.5120928287506104, 0.5044906139373779, 0.519686222076416, 0.5094367265701294, 0.4857637286186218, 0.493855744600296, 0.4839603006839752, 0.4972826838493347, 0.49453771114349365, 0.48309120535850525, 0.5076649785041809, 0.505598247051239, 0.4932062029838562, 0.499056339263916, 0.5136079788208008, 0.46696656942367554, 0.49947667121887207, 0.537865161895752, 0.49020445346832275, 0.4935232400894165, 0.518444299697876, 0.459492027759552, 0.518418550491333, 0.5107964277267456, 0.5159577131271362, 0.5137056112289429, 0.4762391448020935, 0.4948213994503021, 0.5492931008338928, 0.4948514997959137, 0.5032446980476379, 0.5079863667488098, 0.49030300974845886, 0.48511385917663574, 0.5019935965538025, 0.49820756912231445, 0.5324335098266602, 0.5064478516578674, 0.502104640007019, 0.50347501039505, 0.49543496966362, 0.5397997498512268, 0.483296275138855, 0.4648106098175049, 0.5368708372116089, 0.5248487591743469, 0.5079451203346252, 0.4914011061191559, 0.4791994094848633, 0.48145705461502075, 0.49550750851631165, 0.4618864357471466, 0.473899245262146, 0.5190074443817139, 0.46164318919181824, 0.4863225519657135, 0.5113672018051147, 0.4732583165168762, 0.486960232257843, 0.5107557773590088, 0.5032638907432556, 0.49929705262184143, 0.4642379879951477, 0.5130283236503601, 0.504889190196991, 0.49066483974456787, 0.5045919418334961, 0.5024705529212952, 0.5198582410812378, 0.46856212615966797, 0.4639548361301422, 0.5422954559326172, 0.5083298087120056, 0.5402716398239136, 0.5263069868087769, 0.4747430384159088, 0.5333068370819092, 0.5159808993339539, 0.4921293258666992, 0.4982514977455139, 0.4642038941383362, 0.5193033218383789, 0.4990026652812958, 0.49591004848480225, 0.495984822511673, 0.4927181899547577, 0.4674534797668457, 0.48824256658554077, 0.5268442630767822, 0.4914300739765167, 0.5055375099182129, 0.5410749912261963, 0.4501083493232727, 0.4991341233253479, 0.5124855041503906, 0.5172610282897949, 0.5096762180328369, 0.4820641875267029, 0.4946589171886444, 0.46522048115730286, 0.5440850853919983, 0.5019651055335999, 0.4803694486618042, 0.5098620057106018, 0.49754294753074646, 0.48570847511291504, 0.5197064876556396, 0.47713446617126465, 0.4673962891101837, 0.5042587518692017, 0.5106755495071411, 0.4980694353580475, 0.47267359495162964, 0.5173969864845276, 0.4897249937057495, 0.49217042326927185, 0.5193439722061157, 0.48219770193099976, 0.5049910545349121, 0.5090125799179077, 0.4742676317691803, 0.4434734880924225, 0.4678417146205902, 0.478481650352478, 0.518585741519928, 0.48769354820251465, 0.4950103759765625, 0.5579942464828491, 0.4886739253997803, 0.5245124101638794, 0.4834774136543274, 0.4571160078048706, 0.46204495429992676, 0.48611462116241455, 0.493046373128891, 0.49640247225761414, 0.5271564722061157, 0.5113886594772339, 0.46822476387023926, 0.49232345819473267, 0.5250200033187866, 0.5394573211669922, 0.4716298282146454, 0.5206526517868042, 0.5333396196365356, 0.5269935131072998, 0.4807896912097931, 0.5407975912094116, 0.5478471517562866, 0.5027828812599182, 0.49369215965270996, 0.47587865591049194, 0.4881264865398407, 0.4967570900917053, 0.5095944404602051, 0.49070054292678833, 0.47487789392471313, 0.4992309808731079, 0.5187214612960815, 0.4781865179538727, 0.5145190954208374, 0.48148515820503235, 0.49716928601264954, 0.5045023560523987, 0.5071582198143005, 0.5053051114082336, 0.4977509081363678, 0.5136280059814453, 0.5281527042388916, 0.48528212308883667, 0.49358445405960083, 0.47029364109039307, 0.5090718269348145, 0.5098660588264465, 0.48075392842292786, 0.5069604516029358, 0.4722205102443695, 0.5124499797821045, 0.48695245385169983, 0.5132896304130554, 0.4876403212547302, 0.47158321738243103, 0.4938296377658844, 0.49383214116096497, 0.459794819355011, 0.5014992952346802, 0.490727961063385, 0.48281770944595337, 0.5044026374816895, 0.5210732221603394, 0.47462502121925354, 0.48963963985443115, 0.47646909952163696, 0.5187218189239502, 0.4974879026412964, 0.517211377620697, 0.473967581987381, 0.4984828531742096, 0.48967838287353516, 0.5167117118835449, 0.4849958121776581, 0.5058032870292664, 0.5073820352554321, 0.5008805990219116, 0.5313486456871033, 0.5038592219352722, 0.4494413137435913, 0.480629026889801, 0.46463480591773987, 0.504885196685791, 0.493836909532547, 0.5215266942977905, 0.5046329498291016, 0.49522456526756287, 0.4967474639415741, 0.4975667893886566, 0.5265018343925476, 0.4829052984714508, 0.5068702101707458, 0.5000218152999878, 0.5148353576660156, 0.4967818260192871, 0.5138513445854187, 0.47602927684783936, 0.4692612588405609, 0.5234642028808594, 0.4858192503452301, 0.5009963512420654, 0.5050850510597229, 0.5046023726463318, 0.4948873519897461, 0.5165637135505676, 0.46884381771087646, 0.5252698659896851, 0.531341016292572, 0.5037640333175659, 0.5154508352279663, 0.4823540151119232, 0.48496755957603455, 0.4822131395339966, 0.48820602893829346, 0.5122376680374146, 0.47354230284690857, 0.48828911781311035, 0.49414676427841187, 0.48318418860435486, 0.5113478899002075, 0.46372687816619873, 0.5206712484359741, 0.5114486813545227, 0.513378918170929, 0.4989784359931946, 0.5092470645904541, 0.5230163335800171, 0.519973635673523, 0.45791810750961304, 0.4902632534503937, 0.4752855896949768, 0.5234196186065674, 0.47131651639938354, 0.47575122117996216, 0.4897068738937378, 0.5016973614692688, 0.5007355213165283, 0.5007840991020203, 0.4666886031627655, 0.5043886303901672, 0.4936257004737854, 0.5062101483345032, 0.4923427104949951, 0.46854105591773987, 0.49069052934646606, 0.5158963203430176, 0.5104078650474548, 0.48192769289016724, 0.4818625748157501, 0.5049709677696228, 0.48391279578208923, 0.49748605489730835, 0.5133040547370911, 0.46810048818588257, 0.5154067873954773, 0.5036351084709167, 0.5141183137893677, 0.5336419343948364, 0.446765661239624, 0.5235735177993774, 0.5195521116256714, 0.5275894403457642, 0.5144184231758118, 0.5013659596443176, 0.4748285114765167, 0.5113901495933533, 0.5228414535522461, 0.5246102809906006, 0.47999557852745056, 0.49317240715026855, 0.5040283203125, 0.5101372599601746, 0.5042232275009155, 0.4968990385532379, 0.4757597744464874, 0.506611704826355, 0.5178045034408569, 0.46915239095687866, 0.5152498483657837, 0.4860951900482178, 0.5030291676521301, 0.526551365852356, 0.4820215702056885, 0.5222291946411133, 0.46403008699417114, 0.4966959059238434, 0.5188329219818115, 0.5265336036682129, 0.4649266302585602, 0.5101253986358643, 0.4958459138870239, 0.511542797088623, 0.5001325011253357, 0.4901932179927826, 0.49522772431373596, 0.4999964237213135, 0.4902336597442627, 0.5095531940460205, 0.4559275805950165, 0.48689326643943787, 0.48578840494155884, 0.5358376502990723, 0.4916621446609497, 0.4488942325115204, 0.4900847375392914, 0.4950961470603943, 0.48239922523498535, 0.4812251925468445, 0.5142104625701904, 0.4728114902973175, 0.5262921452522278, 0.509714663028717, 0.50142502784729, 0.49346011877059937, 0.4952923357486725, 0.5040584206581116, 0.5219884514808655, 0.5154317021369934, 0.4770791232585907, 0.5007712244987488, 0.5384204387664795, 0.4818948209285736, 0.47207891941070557, 0.5125771164894104, 0.49893730878829956, 0.5100444555282593, 0.5173740983009338, 0.5013894438743591, 0.4975784122943878, 0.4873709976673126, 0.5019710659980774, 0.4989270269870758, 0.5038285851478577, 0.4921751618385315, 0.4986782670021057, 0.550316333770752, 0.48354944586753845, 0.4728649854660034, 0.5036949515342712, 0.45852166414260864, 0.5218384265899658, 0.5380613803863525, 0.47503817081451416, 0.5391978621482849, 0.5231131911277771, 0.5013031363487244, 0.5261418223381042, 0.5263392925262451, 0.501284122467041, 0.5012570023536682, 0.4511161744594574, 0.49852877855300903, 0.4817619025707245, 0.5027487874031067, 0.5119462013244629, 0.49410906434059143, 0.45873576402664185, 0.5012376308441162, 0.4804213345050812, 0.4895515739917755, 0.4969204068183899, 0.5125806331634521, 0.5069894790649414, 0.5262049436569214, 0.47060033679008484, 0.4974905550479889, 0.47502902150154114, 0.5344567894935608, 0.4679073691368103, 0.5227640271186829, 0.46468865871429443, 0.4763156771659851, 0.5092083811759949, 0.5001707673072815, 0.5150175094604492, 0.5078286528587341, 0.48858535289764404, 0.49894022941589355, 0.49461716413497925, 0.480270653963089, 0.5069189667701721, 0.49231889843940735, 0.5068546533584595, 0.4833518862724304, 0.5190231204032898, 0.4872807264328003, 0.48012852668762207, 0.48520177602767944, 0.46819737553596497, 0.4825156629085541, 0.4959081709384918, 0.45441922545433044, 0.5120905041694641, 0.5047206878662109, 0.48573926091194153, 0.4875663220882416, 0.4855137765407562, 0.5050208568572998, 0.4984513819217682, 0.5010414123535156, 0.5089994668960571, 0.5254939198493958, 0.5470231771469116, 0.5028651356697083, 0.46904683113098145, 0.4937978982925415, 0.5289537906646729, 0.534355103969574, 0.46689316630363464, 0.47129541635513306, 0.5464859008789062, 0.5349767804145813, 0.4929807782173157, 0.49184343218803406, 0.5074587464332581, 0.49743497371673584, 0.49841490387916565, 0.4986099600791931, 0.4833080768585205, 0.4747956097126007, 0.4875882565975189, 0.5192708969116211, 0.465575248003006, 0.499803751707077, 0.5364000797271729, 0.4873758554458618, 0.5328394770622253, 0.4972553253173828, 0.5010383129119873, 0.5010568499565125, 0.5338967442512512, 0.49244722723960876, 0.5208510756492615, 0.5048003196716309, 0.49656471610069275, 0.4915978014469147, 0.5159654021263123, 0.5009196996688843, 0.5142151117324829, 0.5479957461357117, 0.4851849377155304, 0.5123661160469055, 0.46774786710739136, 0.4875960350036621, 0.49865204095840454, 0.5141153931617737, 0.4911036491394043, 0.48918282985687256, 0.4916936755180359, 0.49655842781066895, 0.49851229786872864, 0.46593359112739563, 0.4834868907928467, 0.5146759748458862, 0.4948357939720154, 0.4772699773311615, 0.49466952681541443, 0.5068315267562866, 0.5081984996795654, 0.48262593150138855, 0.5006901621818542, 0.47501128911972046, 0.496062308549881, 0.5227132439613342, 0.4943724274635315, 0.4885788559913635, 0.4908290505409241, 0.5280130505561829, 0.5312643647193909, 0.5032147765159607, 0.5333503484725952, 0.4969084560871124, 0.5170844197273254, 0.504723310470581, 0.47833484411239624, 0.5159177184104919, 0.5154886841773987, 0.49611204862594604, 0.511174201965332, 0.48891669511795044, 0.4878392219543457, 0.4932405948638916, 0.48860254883766174, 0.509139895439148, 0.5138905644416809, 0.5020913481712341, 0.5138692855834961, 0.5211822986602783, 0.5208142995834351, 0.4939042925834656, 0.5201830863952637, 0.49463126063346863, 0.46732911467552185, 0.4863085150718689, 0.5019462704658508, 0.5067858099937439, 0.5233279466629028, 0.5010541677474976, 0.48292094469070435, 0.5177137851715088, 0.5077927708625793, 0.5019094347953796, 0.4992990791797638, 0.5132349729537964, 0.485269695520401, 0.4890231788158417, 0.5099613666534424, 0.48335161805152893, 0.4908581078052521, 0.5112771391868591, 0.5046998262405396, 0.497951477766037, 0.518616795539856, 0.5191898345947266, 0.4745732545852661, 0.5002369284629822, 0.5159593820571899, 0.46738332509994507, 0.5229378938674927, 0.4885682761669159, 0.45744869112968445, 0.47606509923934937, 0.4926697015762329, 0.49793538451194763, 0.5216701030731201, 0.5267931222915649, 0.5087048411369324, 0.504433274269104, 0.49497729539871216, 0.4647522568702698, 0.5070948600769043, 0.49585551023483276, 0.5275647640228271, 0.506210207939148, 0.4331963062286377, 0.4851108193397522, 0.47159716486930847, 0.49764081835746765, 0.4999503493309021, 0.5020909309387207, 0.4963172376155853, 0.49948716163635254, 0.497050017118454, 0.5243415236473083, 0.48333871364593506, 0.4901455044746399, 0.5062398314476013, 0.47964218258857727, 0.5039780735969543, 0.5282847881317139, 0.5280972719192505, 0.5038480162620544, 0.5223152041435242, 0.49421456456184387, 0.4934263527393341, 0.5051926374435425, 0.5053703784942627, 0.5274984240531921, 0.5209561586380005, 0.4840726852416992, 0.4772881269454956, 0.519320011138916, 0.5066385865211487, 0.5024195313453674, 0.49095508456230164, 0.47381946444511414, 0.5258991122245789, 0.4915585517883301, 0.4780357778072357, 0.5037450194358826, 0.4859919548034668, 0.5077008008956909, 0.5345603227615356, 0.46893325448036194, 0.5239177346229553, 0.5215365290641785, 0.5214821696281433, 0.4754481911659241, 0.48743635416030884, 0.5117828845977783, 0.5290826559066772, 0.5158352255821228, 0.5132138729095459, 0.4573301672935486, 0.5161058902740479, 0.49302393198013306, 0.5245190262794495, 0.47362300753593445, 0.5144211053848267, 0.4901562035083771, 0.49578365683555603, 0.49313655495643616, 0.4935677945613861, 0.4624459147453308, 0.4851888120174408, 0.5026621222496033, 0.4820527732372284, 0.4843634366989136, 0.5037902593612671, 0.4790642261505127, 0.5026174783706665, 0.5101297497749329, 0.48134857416152954, 0.46696236729621887, 0.5151685476303101, 0.48654207587242126, 0.4703631103038788, 0.4731018543243408, 0.4619373083114624, 0.5080376267433167, 0.5013511180877686, 0.4543120265007019, 0.502993643283844, 0.47437477111816406, 0.5254006385803223, 0.5011477470397949, 0.5075984001159668, 0.5288235545158386, 0.5161188840866089, 0.5263965725898743, 0.5009059906005859, 0.5157653093338013, 0.5138089060783386, 0.478667289018631, 0.4851192235946655, 0.4997626543045044, 0.48454636335372925, 0.49406686425209045, 0.4551849961280823, 0.4839429557323456, 0.44566217064857483, 0.4854466915130615, 0.5007074475288391, 0.48002511262893677, 0.5177412629127502, 0.4653884470462799, 0.5356866717338562, 0.522603452205658, 0.49582070112228394, 0.5127806067466736, 0.49149128794670105, 0.4644728899002075, 0.4800114035606384, 0.4790438115596771, 0.4684121608734131, 0.5046005249023438, 0.5353070497512817, 0.48006686568260193, 0.48921918869018555, 0.5324075222015381, 0.48347437381744385, 0.48294246196746826, 0.4969117045402527, 0.4868509769439697, 0.5268323421478271, 0.5036572813987732, 0.5065051913261414, 0.5052922964096069, 0.5047926902770996, 0.47816744446754456, 0.46923747658729553, 0.48623910546302795, 0.47666996717453003, 0.46963831782341003, 0.53550124168396, 0.4789411425590515, 0.48571398854255676, 0.5322016477584839, 0.5353856086730957, 0.4963676929473877, 0.5219104886054993, 0.49407127499580383, 0.5088849663734436, 0.548984169960022, 0.5022628903388977, 0.4789331555366516, 0.4910508692264557, 0.47005313634872437, 0.453497976064682, 0.4807790517807007, 0.5185379385948181, 0.5256545543670654, 0.5027057528495789, 0.5265882611274719, 0.47617286443710327, 0.4907097816467285, 0.511387288570404, 0.4893171191215515, 0.4968506097793579, 0.5043790340423584, 0.5017247796058655, 0.5156539082527161, 0.4984268248081207, 0.5057677626609802, 0.46964597702026367, 0.4853636622428894, 0.5016226172447205, 0.5186738967895508, 0.5266857147216797, 0.4936085045337677, 0.5227000117301941, 0.47710901498794556, 0.5113507509231567, 0.4845121502876282, 0.4962737262248993, 0.46223318576812744, 0.4861733317375183, 0.4880400002002716, 0.502065122127533, 0.5013432502746582, 0.49019426107406616, 0.492032915353775, 0.46779999136924744, 0.49862733483314514, 0.47613751888275146, 0.5098852515220642, 0.5394338369369507, 0.45619338750839233, 0.5212367177009583, 0.46613559126853943, 0.5265737771987915, 0.5055384635925293, 0.5048962235450745, 0.47488003969192505, 0.503063976764679, 0.5220667719841003, 0.49388349056243896]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tagId</th>\n",
              "      <th>tag</th>\n",
              "      <th>score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>007</td>\n",
              "      <td>0.529151</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>007 (series)</td>\n",
              "      <td>0.455643</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>18th century</td>\n",
              "      <td>0.515348</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1920s</td>\n",
              "      <td>0.476672</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>1930s</td>\n",
              "      <td>0.498028</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1123</th>\n",
              "      <td>1124</td>\n",
              "      <td>writing</td>\n",
              "      <td>0.504896</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1124</th>\n",
              "      <td>1125</td>\n",
              "      <td>wuxia</td>\n",
              "      <td>0.474880</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1125</th>\n",
              "      <td>1126</td>\n",
              "      <td>wwii</td>\n",
              "      <td>0.503064</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1126</th>\n",
              "      <td>1127</td>\n",
              "      <td>zombie</td>\n",
              "      <td>0.522067</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1127</th>\n",
              "      <td>1128</td>\n",
              "      <td>zombies</td>\n",
              "      <td>0.493883</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1128 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      tagId           tag     score\n",
              "0         1           007  0.529151\n",
              "1         2  007 (series)  0.455643\n",
              "2         3  18th century  0.515348\n",
              "3         4         1920s  0.476672\n",
              "4         5         1930s  0.498028\n",
              "...     ...           ...       ...\n",
              "1123   1124       writing  0.504896\n",
              "1124   1125         wuxia  0.474880\n",
              "1125   1126          wwii  0.503064\n",
              "1126   1127        zombie  0.522067\n",
              "1127   1128       zombies  0.493883\n",
              "\n",
              "[1128 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eAN4ll9yyKDE",
        "outputId": "b2ccc2f0-8f95-463d-9460-09c37fc3f309",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "y_hat[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.52978647, 0.4571177 , 0.51454246, 0.475426  , 0.5000681 ,\n",
              "       0.5092914 , 0.49254715, 0.45771247, 0.48527235, 0.4914808 ,\n",
              "       0.4829489 , 0.5044062 , 0.49029827, 0.49527434, 0.4906817 ,\n",
              "       0.47338256, 0.45642036, 0.45541543, 0.52156997, 0.5351796 ,\n",
              "       0.50493836, 0.5155109 , 0.48447353, 0.4906879 , 0.54799217,\n",
              "       0.5223508 , 0.4556455 , 0.5273489 , 0.47761685, 0.5187596 ,\n",
              "       0.5039843 , 0.47404248, 0.51488674, 0.50023186, 0.48526487,\n",
              "       0.48262274, 0.5190196 , 0.4976889 , 0.5398753 , 0.52165836,\n",
              "       0.54379797, 0.5027747 , 0.47691768, 0.48055696, 0.50617737,\n",
              "       0.5018332 , 0.48619285, 0.50598615, 0.46835777, 0.48651668,\n",
              "       0.5365271 , 0.5354549 , 0.50024366, 0.49112722, 0.49763635,\n",
              "       0.4872363 , 0.46656266, 0.49548662, 0.48098394, 0.53529537,\n",
              "       0.5173058 , 0.51332927, 0.53454256, 0.49346298, 0.49212575,\n",
              "       0.5354295 , 0.5059965 , 0.5037043 , 0.47750592, 0.51295257,\n",
              "       0.51311773, 0.5508309 , 0.5171377 , 0.4795404 , 0.51574934,\n",
              "       0.48882952, 0.5219968 , 0.51430875, 0.49827588, 0.4875547 ,\n",
              "       0.50623804, 0.50880075, 0.49402595, 0.49057478, 0.50174874,\n",
              "       0.4983677 , 0.4679602 , 0.4909789 , 0.52636915, 0.5233811 ,\n",
              "       0.46990353, 0.4990381 , 0.48295796, 0.5372095 , 0.4927351 ,\n",
              "       0.4801259 , 0.47258207, 0.5366422 , 0.52281004, 0.49104044,\n",
              "       0.47803587, 0.49859685, 0.4644033 , 0.47777593, 0.53491646,\n",
              "       0.52296954, 0.4518286 , 0.48321408, 0.5232935 , 0.53116566,\n",
              "       0.5106726 , 0.46646988, 0.5239102 , 0.50389767, 0.48504248,\n",
              "       0.48303846, 0.5234565 , 0.48397985, 0.52714634, 0.5285604 ,\n",
              "       0.5051516 , 0.5040007 , 0.52453387, 0.52001077, 0.5285365 ,\n",
              "       0.47719002, 0.51632935, 0.48691496, 0.49014091, 0.4717607 ,\n",
              "       0.5208475 , 0.48555502, 0.49328017, 0.49036056, 0.5032307 ,\n",
              "       0.49916133, 0.5155968 , 0.50896114, 0.5161924 , 0.5181658 ,\n",
              "       0.50015515, 0.5430281 , 0.49121937, 0.45105135, 0.45609665,\n",
              "       0.53452146, 0.47945336, 0.50912297, 0.47450626, 0.49769387,\n",
              "       0.49808854, 0.5323662 , 0.49640447, 0.4942997 , 0.49784213,\n",
              "       0.49503684, 0.4904313 , 0.4804145 , 0.4655064 , 0.4979023 ,\n",
              "       0.4877286 , 0.503665  , 0.52286416, 0.50586224, 0.48715463,\n",
              "       0.5058459 , 0.48577115, 0.5291024 , 0.5143207 , 0.50940084,\n",
              "       0.49519774, 0.5009308 , 0.47696745, 0.5030919 , 0.48540112,\n",
              "       0.48739094, 0.5041572 , 0.49223223, 0.5308395 , 0.5152289 ,\n",
              "       0.48162583, 0.5330291 , 0.5006901 , 0.49367568, 0.4894034 ,\n",
              "       0.4901254 , 0.5177909 , 0.48229694, 0.46044266, 0.48863363,\n",
              "       0.52050346, 0.48436964, 0.50590384, 0.5101547 , 0.50454986,\n",
              "       0.51827675, 0.5013068 , 0.48032588, 0.5001096 , 0.48575494,\n",
              "       0.46461686, 0.49502426, 0.5314621 , 0.51028806, 0.5367771 ,\n",
              "       0.5047078 , 0.53613627, 0.50089467, 0.4659567 , 0.5242473 ,\n",
              "       0.5216642 , 0.48821053, 0.5164661 , 0.49550107, 0.5180612 ,\n",
              "       0.50166076, 0.49688816, 0.46508944, 0.54595524, 0.50082827,\n",
              "       0.5226141 , 0.46392596, 0.5011573 , 0.48442358, 0.49961102,\n",
              "       0.5036794 , 0.49091142, 0.5070661 , 0.47042224, 0.53262526,\n",
              "       0.4882846 , 0.47508305, 0.50278366, 0.48378348, 0.49124926,\n",
              "       0.514664  , 0.52952987, 0.504331  , 0.47524482, 0.49517235,\n",
              "       0.49058908, 0.48785454, 0.48354983, 0.5007283 , 0.5088731 ,\n",
              "       0.5193975 , 0.50149083, 0.48735636, 0.53612673, 0.51570725,\n",
              "       0.5067054 , 0.5050361 , 0.49995756, 0.500549  , 0.50282764,\n",
              "       0.50766987, 0.5224903 , 0.5003448 , 0.4801004 , 0.50106376,\n",
              "       0.52340215, 0.5131302 , 0.45736828, 0.5089606 , 0.53857297,\n",
              "       0.48371467, 0.50004816, 0.47170562, 0.5197933 , 0.48244172,\n",
              "       0.5070604 , 0.4939644 , 0.4904318 , 0.48080572, 0.5044492 ,\n",
              "       0.52148694, 0.5095056 , 0.49545395, 0.5216066 , 0.4787942 ,\n",
              "       0.52581453, 0.4995855 , 0.51691824, 0.53264505, 0.4864651 ,\n",
              "       0.50404406, 0.47931692, 0.47305143, 0.5068526 , 0.52342856,\n",
              "       0.49006906, 0.46010295, 0.49284962, 0.4994293 , 0.47900185,\n",
              "       0.48656148, 0.50513744, 0.46400237, 0.49519035, 0.47735944,\n",
              "       0.49733782, 0.4942732 , 0.48532176, 0.51175916, 0.45921826,\n",
              "       0.5482627 , 0.5133215 , 0.4909666 , 0.5087327 , 0.5070746 ,\n",
              "       0.5022329 , 0.5310002 , 0.5006168 , 0.47683465, 0.49479213,\n",
              "       0.49487686, 0.5021916 , 0.4929748 , 0.49824107, 0.4907616 ,\n",
              "       0.5280789 , 0.47306034, 0.5120539 , 0.4647762 , 0.51177084,\n",
              "       0.52331024, 0.473566  , 0.5519938 , 0.5032941 , 0.5014338 ,\n",
              "       0.52737236, 0.5329185 , 0.49735522, 0.5073536 , 0.47334817,\n",
              "       0.46863228, 0.49576232, 0.5108739 , 0.5195704 , 0.48055562,\n",
              "       0.47189775, 0.48232934, 0.5072893 , 0.5096135 , 0.50890857,\n",
              "       0.49850103, 0.47425246, 0.4855207 , 0.48166046, 0.51646984,\n",
              "       0.49095342, 0.5049354 , 0.48737505, 0.5080968 , 0.48909414,\n",
              "       0.5035559 , 0.510474  , 0.492416  , 0.4911565 , 0.5013019 ,\n",
              "       0.5200741 , 0.49499214, 0.49104798, 0.46392354, 0.49402955,\n",
              "       0.49238467, 0.50472796, 0.4802739 , 0.50802475, 0.54172283,\n",
              "       0.5005223 , 0.49497077, 0.4849725 , 0.50349   , 0.5086371 ,\n",
              "       0.50156415, 0.51895   , 0.51216644, 0.48611182, 0.48912585,\n",
              "       0.48408946, 0.48957282, 0.4906615 , 0.48029765, 0.5112261 ,\n",
              "       0.5079743 , 0.4958458 , 0.49827072, 0.51763326, 0.47760275,\n",
              "       0.49795306, 0.53829134, 0.4869889 , 0.49393186, 0.5117036 ,\n",
              "       0.46553504, 0.5164881 , 0.50923824, 0.51843023, 0.51437545,\n",
              "       0.48183563, 0.49056664, 0.5443313 , 0.49299964, 0.50046784,\n",
              "       0.50787777, 0.49167347, 0.4897771 , 0.4992337 , 0.49594   ,\n",
              "       0.53096974, 0.50745666, 0.4937288 , 0.5080033 , 0.4983294 ,\n",
              "       0.54524064, 0.4781151 , 0.46166834, 0.53261435, 0.52333796,\n",
              "       0.5065771 , 0.4923137 , 0.47249195, 0.48243496, 0.499235  ,\n",
              "       0.46041062, 0.4753397 , 0.51479113, 0.460553  , 0.48328635,\n",
              "       0.51080596, 0.47535923, 0.48611328, 0.50807357, 0.5022943 ,\n",
              "       0.4956235 , 0.4691482 , 0.51440746, 0.5040653 , 0.4899335 ,\n",
              "       0.50857913, 0.5082491 , 0.5174448 , 0.47143656, 0.46758544,\n",
              "       0.54379684, 0.50535756, 0.53406537, 0.52756035, 0.47684556,\n",
              "       0.5355975 , 0.5205923 , 0.4882269 , 0.49683064, 0.45936447,\n",
              "       0.5172902 , 0.49662527, 0.4946926 , 0.49149284, 0.4936978 ,\n",
              "       0.4654854 , 0.48272902, 0.53283197, 0.49540502, 0.49960488,\n",
              "       0.54045635, 0.4496585 , 0.50161695, 0.5120129 , 0.51349145,\n",
              "       0.50989735, 0.48162228, 0.49428532, 0.46753842, 0.54735243,\n",
              "       0.4981212 , 0.4816579 , 0.5126457 , 0.498832  , 0.48441708,\n",
              "       0.5125833 , 0.4775386 , 0.46716306, 0.5058684 , 0.5102883 ,\n",
              "       0.49534863, 0.46985185, 0.5139288 , 0.4878138 , 0.49414784,\n",
              "       0.5213997 , 0.48068148, 0.507849  , 0.5063139 , 0.47961587,\n",
              "       0.442834  , 0.46224156, 0.47809327, 0.5150615 , 0.49073887,\n",
              "       0.49595097, 0.56013876, 0.48716268, 0.5233418 , 0.47720873,\n",
              "       0.4536481 , 0.46161804, 0.4864004 , 0.49000835, 0.4916156 ,\n",
              "       0.5257969 , 0.513287  , 0.46335247, 0.4917864 , 0.52931815,\n",
              "       0.5436121 , 0.4714216 , 0.5223369 , 0.5318803 , 0.52067393,\n",
              "       0.4854304 , 0.53722996, 0.54130024, 0.5055833 , 0.49201778,\n",
              "       0.48102245, 0.48552075, 0.4909604 , 0.5099471 , 0.4904638 ,\n",
              "       0.47782904, 0.4987608 , 0.5219629 , 0.47574437, 0.5173432 ,\n",
              "       0.47701064, 0.49214503, 0.5131056 , 0.5103133 , 0.5061188 ,\n",
              "       0.5019689 , 0.5203703 , 0.52849144, 0.47904068, 0.48741144,\n",
              "       0.4714267 , 0.5169038 , 0.5073711 , 0.4823057 , 0.50895864,\n",
              "       0.46934906, 0.5022939 , 0.49024743, 0.5135331 , 0.4889782 ,\n",
              "       0.47445107, 0.490386  , 0.49468577, 0.46246952, 0.49773887,\n",
              "       0.48763618, 0.48155892, 0.51119196, 0.51128876, 0.4756459 ,\n",
              "       0.4935782 , 0.48323   , 0.51872164, 0.4984492 , 0.51356745,\n",
              "       0.4734001 , 0.49951065, 0.48917952, 0.5225034 , 0.48667893,\n",
              "       0.5032714 , 0.5074129 , 0.5031317 , 0.52456486, 0.50232816,\n",
              "       0.4433943 , 0.47592464, 0.46638858, 0.50968194, 0.49135366,\n",
              "       0.524477  , 0.5041237 , 0.4930459 , 0.49981087, 0.49749976,\n",
              "       0.5230683 , 0.4881206 , 0.5057849 , 0.49851465, 0.52063984,\n",
              "       0.4951997 , 0.52219707, 0.47877637, 0.46784663, 0.52443665,\n",
              "       0.4836086 , 0.5062589 , 0.50112   , 0.5057091 , 0.49246076,\n",
              "       0.52047896, 0.46994528, 0.5203489 , 0.53502905, 0.49885416,\n",
              "       0.51956546, 0.486523  , 0.49058378, 0.47910538, 0.4844607 ,\n",
              "       0.5076948 , 0.47377533, 0.48029107, 0.49540696, 0.47876236,\n",
              "       0.5096872 , 0.46009922, 0.52130866, 0.50648415, 0.51516557,\n",
              "       0.50669557, 0.50668645, 0.52723444, 0.5260819 , 0.45956746,\n",
              "       0.49479762, 0.4717218 , 0.5260855 , 0.47533685, 0.4786106 ,\n",
              "       0.48841625, 0.4996682 , 0.49498817, 0.50826603, 0.47439745,\n",
              "       0.5048491 , 0.49663824, 0.49722314, 0.4888456 , 0.46652663,\n",
              "       0.48453572, 0.5162721 , 0.50338197, 0.47570384, 0.488056  ,\n",
              "       0.49972358, 0.48335186, 0.4980582 , 0.5083047 , 0.46770203,\n",
              "       0.5255789 , 0.50395733, 0.5164633 , 0.53522956, 0.44322956,\n",
              "       0.53188086, 0.5200146 , 0.5302856 , 0.5136002 , 0.49809635,\n",
              "       0.4783259 , 0.51313895, 0.5199642 , 0.51818335, 0.471896  ,\n",
              "       0.49242434, 0.507731  , 0.5139838 , 0.5028059 , 0.4898377 ,\n",
              "       0.47550845, 0.5027531 , 0.5213045 , 0.4656356 , 0.5170252 ,\n",
              "       0.48540944, 0.5095656 , 0.5253055 , 0.48349047, 0.5204529 ,\n",
              "       0.46395382, 0.49257815, 0.51556176, 0.5276117 , 0.46449444,\n",
              "       0.50792164, 0.4908404 , 0.51162195, 0.49361157, 0.49897084,\n",
              "       0.49635723, 0.4984873 , 0.49350408, 0.51412666, 0.44910786,\n",
              "       0.48199034, 0.48204774, 0.5269511 , 0.49121314, 0.45202613,\n",
              "       0.49059457, 0.49463892, 0.4837551 , 0.48024085, 0.5160685 ,\n",
              "       0.4778152 , 0.5198342 , 0.50687385, 0.4934276 , 0.49682102,\n",
              "       0.49361932, 0.49525142, 0.5163939 , 0.5196315 , 0.48192504,\n",
              "       0.50071543, 0.53748727, 0.4750687 , 0.47676077, 0.50724566,\n",
              "       0.49798316, 0.5120453 , 0.5197466 , 0.49927044, 0.5022705 ,\n",
              "       0.49233335, 0.5013717 , 0.49593726, 0.4987443 , 0.49863902,\n",
              "       0.50528044, 0.55154794, 0.48613334, 0.47508037, 0.5000304 ,\n",
              "       0.45722923, 0.52530354, 0.53353363, 0.47803763, 0.54290015,\n",
              "       0.52682227, 0.50403   , 0.52680933, 0.5331494 , 0.49888727,\n",
              "       0.49872273, 0.4483616 , 0.49363983, 0.48446566, 0.5057616 ,\n",
              "       0.50680673, 0.50070286, 0.46012878, 0.50033534, 0.4832909 ,\n",
              "       0.48761508, 0.49418694, 0.5092945 , 0.5109986 , 0.5243065 ,\n",
              "       0.46556604, 0.49760282, 0.47631314, 0.53864837, 0.4715196 ,\n",
              "       0.5292882 , 0.46420482, 0.47779596, 0.50277966, 0.4987678 ,\n",
              "       0.5159449 , 0.5108625 , 0.48533008, 0.49876007, 0.48982868,\n",
              "       0.47311452, 0.5105766 , 0.49288124, 0.50849956, 0.48458835,\n",
              "       0.51476455, 0.49429667, 0.48119804, 0.4865778 , 0.46872604,\n",
              "       0.4814087 , 0.49903637, 0.45949963, 0.51232857, 0.5010851 ,\n",
              "       0.48341647, 0.49196088, 0.48669168, 0.5006962 , 0.49556434,\n",
              "       0.4955619 , 0.5030884 , 0.5280919 , 0.5505074 , 0.49839923,\n",
              "       0.4716145 , 0.49102154, 0.53064674, 0.5384222 , 0.47014073,\n",
              "       0.47379947, 0.5401046 , 0.53093076, 0.49920863, 0.493469  ,\n",
              "       0.5005349 , 0.4972749 , 0.49539122, 0.49440435, 0.48430386,\n",
              "       0.4744032 , 0.49061972, 0.51700884, 0.46951807, 0.49919176,\n",
              "       0.5340802 , 0.4863199 , 0.535082  , 0.5028724 , 0.5065645 ,\n",
              "       0.50373393, 0.5296103 , 0.4990941 , 0.52461314, 0.5015586 ,\n",
              "       0.49813634, 0.49626726, 0.52103674, 0.50753653, 0.5101941 ,\n",
              "       0.54835516, 0.4882581 , 0.5106436 , 0.46544215, 0.4833538 ,\n",
              "       0.4931685 , 0.5153221 , 0.4922358 , 0.483203  , 0.49591768,\n",
              "       0.50427496, 0.49967262, 0.4633086 , 0.48578212, 0.516749  ,\n",
              "       0.49581566, 0.47744703, 0.49894336, 0.50646234, 0.5036081 ,\n",
              "       0.48201284, 0.49629074, 0.4817788 , 0.49713898, 0.5211911 ,\n",
              "       0.4948387 , 0.48344144, 0.49326143, 0.52247167, 0.53226966,\n",
              "       0.50112164, 0.5339034 , 0.49403632, 0.517452  , 0.5090434 ,\n",
              "       0.4770421 , 0.5156295 , 0.518023  , 0.49786612, 0.5095875 ,\n",
              "       0.48916578, 0.48680058, 0.49114585, 0.48419082, 0.5116327 ,\n",
              "       0.51620775, 0.49374646, 0.513387  , 0.5187203 , 0.5233316 ,\n",
              "       0.49023414, 0.52221537, 0.5007736 , 0.46942297, 0.4832073 ,\n",
              "       0.5024093 , 0.5085073 , 0.5198415 , 0.49924558, 0.48169574,\n",
              "       0.51659095, 0.50937057, 0.49923763, 0.49852344, 0.50665754,\n",
              "       0.48532265, 0.49239716, 0.50630414, 0.48480326, 0.4871615 ,\n",
              "       0.5126059 , 0.50858873, 0.5048887 , 0.5191953 , 0.5204852 ,\n",
              "       0.48054263, 0.50527203, 0.515754  , 0.46902835, 0.52589875,\n",
              "       0.4907212 , 0.45661464, 0.4743438 , 0.49429283, 0.49640164,\n",
              "       0.52389115, 0.5289333 , 0.5088323 , 0.50046355, 0.4982063 ,\n",
              "       0.46281126, 0.4981406 , 0.5021045 , 0.53498393, 0.50172037,\n",
              "       0.4366571 , 0.48781958, 0.47202823, 0.49493897, 0.49609873,\n",
              "       0.5027383 , 0.49698538, 0.49882972, 0.4967298 , 0.52182275,\n",
              "       0.4827858 , 0.49280798, 0.5011332 , 0.4812844 , 0.5102171 ,\n",
              "       0.52404135, 0.52879226, 0.50590247, 0.524295  , 0.493453  ,\n",
              "       0.49295574, 0.5124167 , 0.5008719 , 0.5286463 , 0.51437056,\n",
              "       0.48276657, 0.47968563, 0.5170857 , 0.5104315 , 0.5027155 ,\n",
              "       0.49384156, 0.471518  , 0.52400464, 0.48980305, 0.47656593,\n",
              "       0.5115149 , 0.4822664 , 0.5058409 , 0.5334329 , 0.46267232,\n",
              "       0.528614  , 0.5225425 , 0.5196404 , 0.47484908, 0.48128107,\n",
              "       0.51602566, 0.524371  , 0.52313894, 0.5074064 , 0.45294607,\n",
              "       0.51359856, 0.4960832 , 0.52624357, 0.47960085, 0.5147716 ,\n",
              "       0.48682153, 0.49897903, 0.49121407, 0.49772942, 0.4623456 ,\n",
              "       0.48314652, 0.5019082 , 0.48469806, 0.49160787, 0.5071479 ,\n",
              "       0.4767985 , 0.50652635, 0.51093364, 0.4835461 , 0.46247897,\n",
              "       0.5156496 , 0.48904026, 0.46688315, 0.4773382 , 0.45844617,\n",
              "       0.5089953 , 0.5021272 , 0.45693567, 0.4999538 , 0.478613  ,\n",
              "       0.5272373 , 0.50255126, 0.51469314, 0.5298811 , 0.5195153 ,\n",
              "       0.532632  , 0.4960788 , 0.5160857 , 0.5167968 , 0.474618  ,\n",
              "       0.48784   , 0.49997938, 0.48509392, 0.49600774, 0.45630813,\n",
              "       0.4843732 , 0.4445019 , 0.48157358, 0.4968907 , 0.4834888 ,\n",
              "       0.5105696 , 0.46116674, 0.5329641 , 0.51995105, 0.49105006,\n",
              "       0.5098262 , 0.4860498 , 0.46391922, 0.4768811 , 0.4765907 ,\n",
              "       0.46919245, 0.50332   , 0.53290474, 0.48134547, 0.47946975,\n",
              "       0.533674  , 0.4816562 , 0.4803162 , 0.49820504, 0.4862846 ,\n",
              "       0.5310658 , 0.5032959 , 0.50714105, 0.5077777 , 0.50052106,\n",
              "       0.47974962, 0.47526878, 0.48454925, 0.47511277, 0.47950548,\n",
              "       0.5296474 , 0.47993225, 0.4845701 , 0.5272092 , 0.5433802 ,\n",
              "       0.49865276, 0.51875865, 0.49873874, 0.5066085 , 0.5507375 ,\n",
              "       0.5055561 , 0.4817109 , 0.49485722, 0.46124655, 0.45345426,\n",
              "       0.47954327, 0.5208841 , 0.5267905 , 0.5024556 , 0.5253818 ,\n",
              "       0.47355992, 0.4879333 , 0.51535624, 0.48624763, 0.49211302,\n",
              "       0.5066605 , 0.50229514, 0.5178178 , 0.4947372 , 0.5110441 ,\n",
              "       0.46916005, 0.48841742, 0.5010076 , 0.5160215 , 0.5276866 ,\n",
              "       0.4890344 , 0.5246239 , 0.4730316 , 0.51469636, 0.48589292,\n",
              "       0.49745232, 0.4635553 , 0.48360854, 0.48566377, 0.49985793,\n",
              "       0.50232154, 0.48987788, 0.49503595, 0.4668694 , 0.5024224 ,\n",
              "       0.47935933, 0.5090204 , 0.5397919 , 0.45837575, 0.5245698 ,\n",
              "       0.46390527, 0.5283692 , 0.50046426, 0.5066486 , 0.46999925,\n",
              "       0.49911636, 0.5194094 , 0.49115032], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dTkLA8QTJmDs",
        "outputId": "777b4b5c-3408-40fc-eeb8-36b79a59f6a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "y_test[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.059  , 0.05175, 0.024  , 0.027  , 0.049  , 0.0295 , 0.0205 ,\n",
              "       0.051  , 0.0205 , 0.02   , 0.0255 , 0.02275, 0.116  , 0.01375,\n",
              "       0.00225, 0.01975, 0.0085 , 0.07875, 0.8845 , 0.5785 , 0.22575,\n",
              "       0.18725, 0.1    , 0.03225, 0.03975, 0.057  , 0.08175, 0.12275,\n",
              "       0.24075, 0.0875 , 0.005  , 0.02225, 0.043  , 0.0215 , 0.02925,\n",
              "       0.082  , 0.03925, 0.06825, 0.035  , 0.011  , 0.0185 , 0.0205 ,\n",
              "       0.03025, 0.02425, 0.03325, 0.086  , 0.0085 , 0.02875, 0.178  ,\n",
              "       0.1035 , 0.13475, 0.3195 , 0.02925, 0.024  , 0.031  , 0.01375,\n",
              "       0.02875, 0.05175, 0.08225, 0.01875, 0.01525, 0.088  , 0.008  ,\n",
              "       0.0265 , 0.0165 , 0.026  , 0.07925, 0.022  , 0.00875, 0.065  ,\n",
              "       0.008  , 0.0265 , 0.1945 , 0.013  , 0.148  , 0.026  , 0.02975,\n",
              "       0.02825, 0.042  , 0.018  , 0.14275, 0.2985 , 0.104  , 0.04175,\n",
              "       0.10875, 0.115  , 0.03625, 0.0105 , 0.0155 , 0.02375, 0.018  ,\n",
              "       0.0255 , 0.03625, 0.08625, 0.19625, 0.4265 , 0.41225, 0.2515 ,\n",
              "       0.25275, 0.6075 , 0.137  , 0.108  , 0.03625, 0.00375, 0.82325,\n",
              "       0.0025 , 0.13   , 0.03225, 0.136  , 0.0385 , 0.0375 , 0.07475,\n",
              "       0.11675, 0.0085 , 0.13875, 0.0275 , 0.00475, 0.04575, 0.002  ,\n",
              "       0.04425, 0.244  , 0.077  , 0.009  , 0.0345 , 0.037  , 0.057  ,\n",
              "       0.02725, 0.34375, 0.50475, 0.01525, 0.01175, 0.6015 , 0.01775,\n",
              "       0.013  , 0.0205 , 0.015  , 0.0185 , 0.12175, 0.01875, 0.0135 ,\n",
              "       0.07075, 0.012  , 0.02875, 0.1555 , 0.0315 , 0.057  , 0.011  ,\n",
              "       0.0275 , 0.04825, 0.04975, 0.06175, 0.024  , 0.035  , 0.146  ,\n",
              "       0.162  , 0.0895 , 0.06275, 0.01175, 0.013  , 0.07325, 0.00625,\n",
              "       0.077  , 0.00725, 0.06575, 0.00825, 0.01675, 0.04225, 0.031  ,\n",
              "       0.2715 , 0.0725 , 0.09425, 0.1025 , 0.15475, 0.0185 , 0.09975,\n",
              "       0.08825, 0.056  , 0.0425 , 0.07525, 0.0155 , 0.27425, 0.04025,\n",
              "       0.4515 , 0.0365 , 0.181  , 0.021  , 0.04325, 0.64825, 0.05525,\n",
              "       0.024  , 0.04925, 0.138  , 0.041  , 0.0395 , 0.794  , 0.0845 ,\n",
              "       0.02575, 0.1065 , 0.032  , 0.02875, 0.06925, 0.01225, 0.122  ,\n",
              "       0.17575, 0.0135 , 0.05175, 0.016  , 0.0215 , 0.012  , 0.011  ,\n",
              "       0.222  , 0.17075, 0.0095 , 0.012  , 0.04125, 0.14875, 0.00725,\n",
              "       0.09075, 0.001  , 0.2565 , 0.0855 , 0.1495 , 0.0095 , 0.0135 ,\n",
              "       0.0055 , 0.04825, 0.022  , 0.0125 , 0.0505 , 0.0555 , 0.06675,\n",
              "       0.03375, 0.03275, 0.0525 , 0.0805 , 0.03975, 0.006  , 0.0255 ,\n",
              "       0.018  , 0.264  , 0.039  , 0.06925, 0.07325, 0.205  , 0.13025,\n",
              "       0.549  , 0.0375 , 0.04125, 0.0165 , 0.0265 , 0.42825, 0.338  ,\n",
              "       0.02525, 0.01625, 0.1655 , 0.05575, 0.05425, 0.34525, 0.05625,\n",
              "       0.09875, 0.025  , 0.04325, 0.0195 , 0.18125, 0.0245 , 0.20575,\n",
              "       0.037  , 0.1005 , 0.08975, 0.15525, 0.01975, 0.213  , 0.01175,\n",
              "       0.045  , 0.06525, 0.12725, 0.32675, 0.07175, 0.06   , 0.022  ,\n",
              "       0.018  , 0.037  , 0.013  , 0.02375, 0.02825, 0.04975, 0.04   ,\n",
              "       0.12725, 0.01275, 0.01375, 0.0025 , 0.188  , 0.0385 , 0.07025,\n",
              "       0.0065 , 0.0085 , 0.0395 , 0.04025, 0.22775, 0.06975, 0.0755 ,\n",
              "       0.4505 , 0.01925, 0.067  , 0.02075, 0.0275 , 0.0975 , 0.2995 ,\n",
              "       0.041  , 0.00975, 0.06925, 0.054  , 0.1555 , 0.19625, 0.01475,\n",
              "       0.43925, 0.087  , 0.01875, 0.0435 , 0.01125, 0.00875, 0.05   ,\n",
              "       0.1295 , 0.181  , 0.056  , 0.04325, 0.04375, 0.103  , 0.02075,\n",
              "       0.01675, 0.01025, 0.08775, 0.0525 , 0.12375, 0.41575, 0.05375,\n",
              "       0.01975, 0.14125, 0.049  , 0.007  , 0.0225 , 0.01425, 0.03   ,\n",
              "       0.02525, 0.02725, 0.02725, 0.00625, 0.12925, 0.0565 , 0.04875,\n",
              "       0.10675, 0.01025, 0.07675, 0.04475, 0.53475, 0.224  , 0.02275,\n",
              "       0.078  , 0.042  , 0.1695 , 0.33325, 0.08025, 0.0205 , 0.15725,\n",
              "       0.1965 , 0.16325, 0.5475 , 0.09325, 0.25725, 0.0505 , 0.03925,\n",
              "       0.0225 , 0.011  , 0.75175, 0.1665 , 0.464  , 0.175  , 0.2915 ,\n",
              "       0.0475 , 0.0075 , 0.10975, 0.632  , 0.06675, 0.0235 , 0.02025,\n",
              "       0.3125 , 0.14425, 0.13125, 0.4435 , 0.0905 , 0.0315 , 0.011  ,\n",
              "       0.062  , 0.02725, 0.0285 , 0.326  , 0.016  , 0.01475, 0.0115 ,\n",
              "       0.0065 , 0.15775, 0.036  , 0.08325, 0.01625, 0.024  , 0.283  ,\n",
              "       0.02125, 0.01225, 0.014  , 0.02025, 0.0305 , 0.08125, 0.0185 ,\n",
              "       0.13275, 0.2785 , 0.0135 , 0.03625, 0.02725, 0.05025, 0.09125,\n",
              "       0.04575, 0.079  , 0.03625, 0.12825, 0.036  , 0.06175, 0.17275,\n",
              "       0.2575 , 0.03675, 0.023  , 0.021  , 0.027  , 0.02725, 0.015  ,\n",
              "       0.0325 , 0.067  , 0.05525, 0.004  , 0.136  , 0.02075, 0.0435 ,\n",
              "       0.05875, 0.07375, 0.05175, 0.4925 , 0.487  , 0.784  , 0.241  ,\n",
              "       0.065  , 0.0835 , 0.042  , 0.3    , 0.104  , 0.106  , 0.0475 ,\n",
              "       0.01125, 0.024  , 0.0855 , 0.04025, 0.045  , 0.09325, 0.03275,\n",
              "       0.115  , 0.29375, 0.26075, 0.02925, 0.0295 , 0.48875, 0.15975,\n",
              "       0.0335 , 0.073  , 0.322  , 0.03   , 0.20375, 0.08525, 0.01425,\n",
              "       0.016  , 0.106  , 0.06675, 0.01125, 0.0935 , 0.09225, 0.02375,\n",
              "       0.68825, 0.8625 , 0.01525, 0.0055 , 0.014  , 0.00325, 0.368  ,\n",
              "       0.10025, 0.0105 , 0.14825, 0.02175, 0.0655 , 0.01975, 0.0435 ,\n",
              "       0.60325, 0.009  , 0.01   , 0.1065 , 0.07825, 0.066  , 0.066  ,\n",
              "       0.0295 , 0.00975, 0.06325, 0.0595 , 0.01375, 0.02475, 0.04   ,\n",
              "       0.05725, 0.0355 , 0.05075, 0.00825, 0.055  , 0.007  , 0.01125,\n",
              "       0.19925, 0.02325, 0.37875, 0.029  , 0.0485 , 0.0925 , 0.6605 ,\n",
              "       0.06625, 0.0515 , 0.035  , 0.07275, 0.06675, 0.052  , 0.147  ,\n",
              "       0.33175, 0.0045 , 0.02675, 0.15175, 0.0445 , 0.07075, 0.02075,\n",
              "       0.03025, 0.004  , 0.064  , 0.07425, 0.02825, 0.17325, 0.02225,\n",
              "       0.01575, 0.134  , 0.046  , 0.15725, 0.1035 , 0.025  , 0.4115 ,\n",
              "       0.13825, 0.517  , 0.1575 , 0.05025, 0.10325, 0.00475, 0.027  ,\n",
              "       0.029  , 0.07275, 0.01975, 0.088  , 0.0445 , 0.01275, 0.0775 ,\n",
              "       0.0865 , 0.01175, 0.0325 , 0.006  , 0.01625, 0.00575, 0.024  ,\n",
              "       0.0105 , 0.00975, 0.00875, 0.00975, 0.03675, 0.0405 , 0.046  ,\n",
              "       0.044  , 0.0615 , 0.05325, 0.2385 , 0.0635 , 0.84925, 0.05575,\n",
              "       0.15375, 0.007  , 0.00375, 0.0255 , 0.00375, 0.36425, 0.0805 ,\n",
              "       0.02475, 0.1225 , 0.06625, 0.009  , 0.04175, 0.23425, 0.345  ,\n",
              "       0.1025 , 0.02475, 0.0215 , 0.0535 , 0.03175, 0.05125, 0.34625,\n",
              "       0.1455 , 0.0745 , 0.06375, 0.05525, 0.166  , 0.03875, 0.01875,\n",
              "       0.0105 , 0.0135 , 0.052  , 0.081  , 0.055  , 0.019  , 0.076  ,\n",
              "       0.03475, 0.12975, 0.02   , 0.28425, 0.00975, 0.08375, 0.0555 ,\n",
              "       0.01825, 0.019  , 0.004  , 0.044  , 0.01925, 0.0065 , 0.02925,\n",
              "       0.015  , 0.01825, 0.1415 , 0.0485 , 0.093  , 0.0865 , 0.0055 ,\n",
              "       0.08325, 0.46725, 0.009  , 0.00875, 0.04825, 0.0175 , 0.036  ,\n",
              "       0.04   , 0.014  , 0.0515 , 0.0205 , 0.02275, 0.0065 , 0.03625,\n",
              "       0.0145 , 0.0455 , 0.1975 , 0.01025, 0.03525, 0.034  , 0.00525,\n",
              "       0.02425, 0.01875, 0.12625, 0.06575, 0.03175, 0.012  , 0.03725,\n",
              "       0.04225, 0.03075, 0.04725, 0.02125, 0.02675, 0.0065 , 0.1625 ,\n",
              "       0.00975, 0.0455 , 0.40425, 0.097  , 0.0225 , 0.019  , 0.04075,\n",
              "       0.02   , 0.05525, 0.04125, 0.05825, 0.03175, 0.081  , 0.0135 ,\n",
              "       0.507  , 0.009  , 0.01425, 0.01975, 0.00675, 0.00475, 0.016  ,\n",
              "       0.04725, 0.08125, 0.1445 , 0.03575, 0.09075, 0.00975, 0.05175,\n",
              "       0.005  , 0.19475, 0.10025, 0.012  , 0.01925, 0.04875, 0.02   ,\n",
              "       0.0435 , 0.02125, 0.08425, 0.1085 , 0.31825, 0.1075 , 0.02325,\n",
              "       0.0225 , 0.03775, 0.013  , 0.0315 , 0.20525, 0.138  , 0.02   ,\n",
              "       0.13825, 0.032  , 0.34825, 0.0525 , 0.07725, 0.076  , 0.041  ,\n",
              "       0.01625, 0.0525 , 0.006  , 0.03325, 0.008  , 0.013  , 0.6645 ,\n",
              "       0.178  , 0.017  , 0.1685 , 0.02775, 0.10125, 0.0255 , 0.04075,\n",
              "       0.1595 , 0.0475 , 0.10725, 0.05025, 0.01   , 0.01825, 0.027  ,\n",
              "       0.02875, 0.05375, 0.12575, 0.0495 , 0.145  , 0.03075, 0.2985 ,\n",
              "       0.0095 , 0.0965 , 0.07225, 0.08625, 0.11975, 0.033  , 0.03825,\n",
              "       0.1845 , 0.021  , 0.03125, 0.07425, 0.00475, 0.0495 , 0.76875,\n",
              "       0.0765 , 0.0475 , 0.071  , 0.01925, 0.024  , 0.01075, 0.00375,\n",
              "       0.00475, 0.0105 , 0.61825, 0.714  , 0.18775, 0.031  , 0.02275,\n",
              "       0.17125, 0.06675, 0.03525, 0.09175, 0.2885 , 0.3025 , 0.02925,\n",
              "       0.047  , 0.0495 , 0.24725, 0.03025, 0.02625, 0.068  , 0.01525,\n",
              "       0.04825, 0.748  , 0.0175 , 0.0875 , 0.017  , 0.133  , 0.0185 ,\n",
              "       0.08375, 0.0555 , 0.0185 , 0.397  , 0.00625, 0.0365 , 0.03925,\n",
              "       0.005  , 0.046  , 0.01625, 0.1695 , 0.09275, 0.20175, 0.00425,\n",
              "       0.02625, 0.131  , 0.13875, 0.066  , 0.0085 , 0.05975, 0.05375,\n",
              "       0.12225, 0.03225, 0.05525, 0.038  , 0.01625, 0.03875, 0.11525,\n",
              "       0.153  , 0.1725 , 0.06775, 0.20525, 0.12375, 0.094  , 0.048  ,\n",
              "       0.01075, 0.20325, 0.246  , 0.05175, 0.13825, 0.0105 , 0.10825,\n",
              "       0.05025, 0.01325, 0.144  , 0.06275, 0.03125, 0.03525, 0.0405 ,\n",
              "       0.01225, 0.1365 , 0.22425, 0.1195 , 0.009  , 0.296  , 0.06725,\n",
              "       0.03175, 0.1735 , 0.036  , 0.051  , 0.01175, 0.14925, 0.05675,\n",
              "       0.02425, 0.0445 , 0.10225, 0.02225, 0.0415 , 0.0525 , 0.20425,\n",
              "       0.16775, 0.0125 , 0.081  , 0.1845 , 0.08175, 0.0745 , 0.14075,\n",
              "       0.087  , 0.04375, 0.026  , 0.05025, 0.02925, 0.27375, 0.341  ,\n",
              "       0.504  , 0.076  , 0.04125, 0.0895 , 0.0585 , 0.09425, 0.03125,\n",
              "       0.1145 , 0.02225, 0.02175, 0.03   , 0.03775, 0.03025, 0.118  ,\n",
              "       0.387  , 0.005  , 0.1455 , 0.01825, 0.05125, 0.008  , 0.01325,\n",
              "       0.0135 , 0.175  , 0.23375, 0.125  , 0.23   , 0.01975, 0.011  ,\n",
              "       0.017  , 0.14275, 0.0185 , 0.03875, 0.04025, 0.018  , 0.101  ,\n",
              "       0.0635 , 0.54175, 0.0615 , 0.0085 , 0.1015 , 0.13475, 0.00475,\n",
              "       0.00725, 0.0065 , 0.02225, 0.054  , 0.06175, 0.041  , 0.03825,\n",
              "       0.014  , 0.01725, 0.02725, 0.03425, 0.056  , 0.28525, 0.136  ,\n",
              "       0.03575, 0.0145 , 0.21675, 0.09575, 0.01475, 0.024  , 0.019  ,\n",
              "       0.4235 , 0.466  , 0.0285 , 0.0365 , 0.01   , 0.02475, 0.05225,\n",
              "       0.18125, 0.07725, 0.012  , 0.00325, 0.29575, 0.31425, 0.07475,\n",
              "       0.0155 , 0.009  , 0.00475, 0.05625, 0.22325, 0.0915 , 0.118  ,\n",
              "       0.05125, 0.08975, 0.039  , 0.05   , 0.014  , 0.01475, 0.1535 ,\n",
              "       0.072  , 0.1655 , 0.213  , 0.06   , 0.19075, 0.0085 , 0.075  ,\n",
              "       0.076  , 0.035  , 0.67375, 0.232  , 0.778  , 0.6475 , 0.064  ,\n",
              "       0.00275, 0.03675, 0.107  , 0.032  , 0.021  , 0.0475 , 0.1575 ,\n",
              "       0.00625, 0.06675, 0.068  , 0.5955 , 0.14975, 0.20625, 0.041  ,\n",
              "       0.03   , 0.0875 , 0.027  , 0.00725, 0.24675, 0.0215 , 0.0665 ,\n",
              "       0.05425, 0.106  , 0.60875, 0.06975, 0.01875, 0.016  , 0.05275,\n",
              "       0.016  , 0.84175, 0.0905 , 0.0815 , 0.218  , 0.069  , 0.0125 ,\n",
              "       0.04125, 0.0075 , 0.0085 , 0.171  , 0.0145 , 0.0155 , 0.02125,\n",
              "       0.0705 , 0.0635 , 0.096  , 0.0585 , 0.02725, 0.22925, 0.16625,\n",
              "       0.67925, 0.04025, 0.08875, 0.12575, 0.024  , 0.01425, 0.27975,\n",
              "       0.0715 , 0.0095 , 0.014  , 0.06475, 0.121  , 0.417  , 0.19425,\n",
              "       0.04975, 0.0505 , 0.01575, 0.06825, 0.007  , 0.26075, 0.1995 ,\n",
              "       0.1225 , 0.128  , 0.07125, 0.0295 , 0.014  , 0.017  , 0.01375,\n",
              "       0.006  , 0.003  , 0.044  , 0.11875, 0.04325, 0.24825, 0.13325,\n",
              "       0.0495 , 0.037  , 0.0885 , 0.07375, 0.0935 , 0.1615 , 0.13625,\n",
              "       0.0515 , 0.0215 , 0.05325, 0.02725, 0.02875, 0.0505 , 0.08625,\n",
              "       0.04025, 0.24675, 0.02275, 0.0265 , 0.0725 , 0.079  , 0.0245 ,\n",
              "       0.02125, 0.09075, 0.10975, 0.06025, 0.02575, 0.02525, 0.02975,\n",
              "       0.09375, 0.03225, 0.13425, 0.017  , 0.0555 , 0.019  , 0.01325,\n",
              "       0.02075, 0.01775, 0.2405 , 0.047  , 0.01275, 0.01775, 0.0855 ,\n",
              "       0.01675], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2wdR1iEb_FFF"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
